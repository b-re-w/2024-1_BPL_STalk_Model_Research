{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "[Deep Speaker](https://github.com/philipperemy/deep-speaker)",
   "id": "235a3ff85e5714f5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from deep_speaker.audio import read_mfcc\n",
    "from deep_speaker.batcher import sample_from_mfcc\n",
    "from deep_speaker.constants import SAMPLE_RATE, NUM_FRAMES\n",
    "from deep_speaker.conv_models import DeepSpeakerModel\n",
    "from deep_speaker.test import batch_cosine_similarity\n",
    "\n",
    "# Reproducible results.\n",
    "np.random.seed(123)\n",
    "random.seed(123)\n",
    "\n",
    "# Define the model here.\n",
    "model = DeepSpeakerModel()\n",
    "\n",
    "# Load the checkpoint. https://drive.google.com/file/d/1F9NvdrarWZNktdX9KlRYWWHDwRkip_aP.\n",
    "# Also available here: https://share.weiyun.com/V2suEUVh (Chinese users).\n",
    "model.m.load_weights('ResCNN_triplet_training_checkpoint_265.h5', by_name=True)\n",
    "\n",
    "# Sample some inputs for WAV/FLAC files for the same speaker.\n",
    "# To have reproducible results every time you call this function, set the seed every time before calling it.\n",
    "# np.random.seed(123)\n",
    "# random.seed(123)\n",
    "mfcc_001 = sample_from_mfcc(read_mfcc('samples/PhilippeRemy/PhilippeRemy_001.wav', SAMPLE_RATE), NUM_FRAMES)\n",
    "mfcc_002 = sample_from_mfcc(read_mfcc('samples/PhilippeRemy/PhilippeRemy_002.wav', SAMPLE_RATE), NUM_FRAMES)\n",
    "\n",
    "# Call the model to get the embeddings of shape (1, 512) for each file.\n",
    "predict_001 = model.m.predict(np.expand_dims(mfcc_001, axis=0))\n",
    "predict_002 = model.m.predict(np.expand_dims(mfcc_002, axis=0))\n",
    "\n",
    "# Do it again with a different speaker.\n",
    "mfcc_003 = sample_from_mfcc(read_mfcc('samples/1255-90413-0001.flac', SAMPLE_RATE), NUM_FRAMES)\n",
    "predict_003 = model.m.predict(np.expand_dims(mfcc_003, axis=0))\n",
    "\n",
    "# Compute the cosine similarity and check that it is higher for the same speaker.\n",
    "print('SAME SPEAKER', batch_cosine_similarity(predict_001, predict_002)) # SAME SPEAKER [0.81564593]\n",
    "print('DIFF SPEAKER', batch_cosine_similarity(predict_001, predict_003)) # DIFF SPEAKER [0.1419204]"
   ],
   "id": "c1ad730a7f32060e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
