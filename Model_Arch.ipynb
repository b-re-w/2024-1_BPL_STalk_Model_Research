{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# STalk Model Architecture",
   "id": "7735c9f892bfde57"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Preparation",
   "id": "8dd61067cd95c518"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "USE_CUDA = False",
   "id": "9504df697eb20002",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "!pip install huggingface_hub transformers",
   "id": "cf224e2df50dc3ac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "!pip install intel-npu-acceleration-library",
   "id": "16c6a20ce68f6b47",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if USE_CUDA:\n",
    "    !pip uninstall torch torchvision torchaudio -y\n",
    "    !pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "else:\n",
    "    !pip uninstall torch torchvision torchaudio -y\n",
    "    !pip install torch torchvision torchaudio"
   ],
   "id": "78b5e20d2e4794ed",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "if USE_CUDA:\n",
    "    !pip uninstall llama-cpp-python -y\n",
    "    !pip install llama-cpp-python --extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cu121\n",
    "else:\n",
    "    !pip uninstall llama-cpp-python -y\n",
    "    !pip install llama-cpp-python --extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cpu"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "!pip install pyannote-audio",
   "id": "c8a543d6de42e52a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "!pip install faster-whisper",
   "id": "5d9fa892f0cca9f6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "!pip install git+https://github.com/wenet-e2e/wespeaker.git",
   "id": "e98497e9df4c9237",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "!pip install pyaudio",
   "id": "aee2deb6480d288b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Initialize Pretrained Model",
   "id": "52b6bde35783ad11"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import intel_npu_acceleration_library\n",
    "\n",
    "from multiprocessing import Process, Manager\n",
    "\n",
    "import os\n",
    "import gc\n",
    "\n",
    "import wave\n",
    "import pyaudio\n",
    "\n",
    "import torch\n",
    "import torchaudio\n",
    "\n",
    "from llama_cpp import Llama\n",
    "\n",
    "from pyannote.audio import Audio\n",
    "from pyannote.core import Segment\n",
    "\n",
    "from faster_whisper import WhisperModel\n",
    "\n",
    "from huggingface_hub import hf_hub_download\n",
    "import wespeaker\n",
    "\n",
    "DEVICE = \"cuda\"\n",
    "if not torch.cuda.is_available():\n",
    "    DEVICE = \"cpu\"\n",
    "    print(\"INFO: CUDA is diabled on this machine.\\n\")\n",
    "\n",
    "print(\"PyTorch:\", torch.__version__)\n",
    "print(\"TorchAudio:\", torchaudio.__version__)\n",
    "print(\"Uses Device:\", DEVICE.upper())"
   ],
   "id": "5ac9644848ee0e4c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class ChatHistory(list):\n",
    "    messages = []\n",
    "    \n",
    "    @classmethod\n",
    "    def add_messages(cls, role, content):\n",
    "        if isinstance(content, str):\n",
    "            cls.messages.append({ 'role': role, 'content': content })\n",
    "        else:\n",
    "            for r, c in zip(role, content):\n",
    "                cls.messages.append({ 'role': r, 'content': c })\n",
    "    \n",
    "    @classmethod\n",
    "    def create_prompt(cls, system_prompt: str, user_prompt: str = \"\"):\n",
    "        return [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system_prompt\n",
    "            },\n",
    "            *cls.messages,\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": user_prompt\n",
    "            }\n",
    "        ]"
   ],
   "id": "af46f0c60c545b42",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def token_stream(token):\n",
    "    delta = token[\"choices\"][0][\"delta\"]\n",
    "    if \"content\" not in delta:\n",
    "        return \"\"\n",
    "    else:\n",
    "        return delta[\"content\"]"
   ],
   "id": "4d3d90098a358928",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_llama3():\n",
    "    model_id = \"lmstudio-community/Meta-Llama-3-8B-Instruct-GGUF\"\n",
    "\n",
    "    chat = Llama.from_pretrained(\n",
    "        repo_id=model_id,\n",
    "        filename=\"*Q4_K_M.gguf\",\n",
    "        #chat_format=\"llama-3\",\n",
    "        verbose=False\n",
    "    ).create_chat_completion\n",
    "    \n",
    "    def llama3(system_prompt, user_prompt, temp=0.5, show_prompt=False):\n",
    "        prompt = ChatHistory.create_prompt(system_prompt, user_prompt)\n",
    "\n",
    "        if show_prompt:\n",
    "            print(\"PROMPT:\")\n",
    "            for line in prompt:\n",
    "                print(line)\n",
    "            print()\n",
    "        \n",
    "        return chat(prompt, temperature=temp, stream=True)\n",
    "    \n",
    "    return llama3"
   ],
   "id": "dcc08e168c69e1b0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_whisper():\n",
    "    model_size = \"medium\"  #@param ['tiny', 'base', 'small', 'medium', 'large', 'large-v2', 'large-v3']\n",
    "    compute_type = \"int8\"  #@param ['float16', 'int8']\n",
    "\n",
    "    return WhisperModel(model_size, device=DEVICE, cpu_threads=12, compute_type=compute_type).transcribe"
   ],
   "id": "b89792661b6ec828",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def extract_embedding(model, pcm, sample_rate):\n",
    "    pcm = pcm.to(torch.float)\n",
    "    if sample_rate != model.resample_rate:\n",
    "        pcm = torchaudio.transforms.Resample(\n",
    "            orig_freq=sample_rate, new_freq=model.resample_rate)(pcm)\n",
    "    feats = model.compute_fbank(\n",
    "        pcm,\n",
    "        sample_rate=model.resample_rate,\n",
    "        cmn=True\n",
    "    )\n",
    "    feats = feats.unsqueeze(0)\n",
    "    feats = feats.to(model.device)\n",
    "    model.model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model.model(feats)\n",
    "        outputs = outputs[-1] if isinstance(outputs, tuple) else outputs\n",
    "    embedding = outputs[0].to(torch.device('cpu'))\n",
    "    return embedding"
   ],
   "id": "30d64a4f6687bd63",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def recognize(model, pcm, sample_rate):\n",
    "    q = extract_embedding(model, pcm, sample_rate)\n",
    "    best_score = 0.0\n",
    "    best_name = ''\n",
    "    for name, e in model.table.items():\n",
    "        score = model.cosine_similarity(q, e)\n",
    "        if best_score < score:\n",
    "            best_score = score\n",
    "            best_name = name\n",
    "        del score\n",
    "        gc.collect()\n",
    "    return {'name': best_name, 'confidence': best_score}"
   ],
   "id": "afa012c69b8b6bfb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_resnet152():\n",
    "    model_id = \"Wespeaker/wespeaker-voxceleb-resnet152-LM\"\n",
    "    model_name = model_id.replace(\"Wespeaker/wespeaker-\", \"\").replace(\"-\", \"_\")\n",
    "    \n",
    "    root_dir = hf_hub_download(model_id, filename=model_name+\".onnx\").replace(model_name+\".onnx\", \"\")\n",
    "    \n",
    "    import os\n",
    "    if not os.path.isfile(root_dir+\"avg_model.pt\"):\n",
    "        os.rename(hf_hub_download(model_id, filename=model_name+\".pt\"), root_dir+\"avg_model.pt\")\n",
    "    if not os.path.isfile(root_dir+\"config.yaml\"):\n",
    "        os.rename(hf_hub_download(model_id, filename=model_name+\".yaml\"), root_dir+\"config.yaml\")\n",
    "\n",
    "    resnet = wespeaker.load_model_local(root_dir)\n",
    "\n",
    "    #print(\"Compile model for the NPU\")\n",
    "    #resnet.model = intel_npu_acceleration_library.compile(resnet.model)\n",
    "    \n",
    "    def resnet152(ado, sample_rate=None):\n",
    "        if isinstance(ado, str):\n",
    "            return resnet.recognize(ado)\n",
    "        else:\n",
    "            return recognize(resnet, ado, sample_rate)\n",
    "    \n",
    "    resnet152.__dict__['register'] = lambda *args, **kwargs: resnet.register(*args, **kwargs)\n",
    "    \n",
    "    return resnet152"
   ],
   "id": "749f1c87edfcaf13",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "llama3 = get_llama3()\n",
    "print(\"INFO: Llama3 Ready -\", llama3)"
   ],
   "id": "84afaa73fc994074",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "whisper = get_whisper()\n",
    "print(\"INFO: Whisper Ready -\", whisper)"
   ],
   "id": "60e076b7f0b0d8d8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "audio = Audio()\n",
    "resnet152 = get_resnet152()\n",
    "print(\"INFO: ResNet152 Ready -\", resnet152)"
   ],
   "id": "37aad593f186941f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model Ready",
   "id": "7822a1e86b0b13cc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Insert System Chat Template to Llama3",
   "id": "aed1f7b006c23d26"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "system_prompt = \"You are a helpful, smart, kind, and efficient Conversation Analysis and Recommendation AI System. You always fulfill the user's requests to the best of your ability. You need to keep listen to the conversations. Please answer in Korean language.\"",
   "id": "57604fee7594a215",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for chunk in llama3(system_prompt, \"\"):\n",
    "    print(token_stream(chunk), end=\"\", flush=True)\n",
    "print()"
   ],
   "id": "3440563cb7b1e8a8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Speaker Registration to ResNet293",
   "id": "394a61aaef06b005"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "speaker1 = \"민서\", \"./SpeakerDiarization/sample_conversation/real/sentence_F.wav\"\n",
    "speaker2 = \"연우\", \"./SpeakerDiarization/sample_conversation/real/sentence_M.wav\"\n",
    "speaker1, speaker2"
   ],
   "id": "d7d65905c9926461",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "resnet152.register(*speaker1)\n",
    "resnet152.register(*speaker2)"
   ],
   "id": "4d5bb1d046f05f3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "user_prompt = f\"Based on the conversations between {speaker1[0]} and {speaker2[0]}, on be half of {speaker2[0]}, do recommend a new topic sentence related the current situation or their personal interests.\"",
   "id": "3b996069095274d4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Run",
   "id": "4794a7f2135b1fbd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "TEST_MODE = False",
   "id": "bfd4170a9eb3cbec",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "RECORD_FORMAT = pyaudio.paInt16\n",
    "RECORD_RATE = 44100\n",
    "RECORD_CHANNELS = 1\n",
    "RECORD_CHUNK = 1024\n",
    "recoder = pyaudio.PyAudio()"
   ],
   "id": "6f29cc187768259d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "RECORD_SECONDS = 1\n",
    "FRAME_LENGTH = int(RECORD_RATE / RECORD_CHUNK * RECORD_SECONDS)\n",
    "\n",
    "CACHE_FOLDER = os.path.join(\".\", \"cache\")\n",
    "OUTPUT_FILENAME = \"conversation_output.wav\"\n",
    "\n",
    "if not os.path.isdir(CACHE_FOLDER):\n",
    "    os.mkdir(CACHE_FOLDER)"
   ],
   "id": "a267362d9045abd5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def play_test_audio():\n",
    "    audio_path = \"./SpeakerDiarization/sample_conversation/real/conversation_0530_out.wav\"\n",
    "    test_file = wave.open(audio_path, \"rb\")\n",
    "\n",
    "    player = recoder.open(\n",
    "        format=recoder.get_format_from_width(test_file.getsampwidth()),\n",
    "        channels=test_file.getnchannels(),\n",
    "        rate=test_file.getframerate(),\n",
    "        output=True,\n",
    "        stream_callback=lambda _, frame_count, __, ___: (test_file.readframes(frame_count), pyaudio.paContinue)\n",
    "    )\n",
    "\n",
    "    player.start_stream()\n",
    "    print(\"Playing test audio...\")\n",
    "    \n",
    "    while player.is_active():\n",
    "        sleep(0.1)\n",
    "\n",
    "    player.stop_stream()\n",
    "    player.close()"
   ],
   "id": "7ce11f83da97573",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def record_audio(params):\n",
    "    stream = recoder.open(\n",
    "        format=RECORD_FORMAT, channels=RECORD_CHANNELS,\n",
    "        rate=RECORD_RATE, input=True,\n",
    "        frames_per_buffer=RECORD_CHUNK\n",
    "    )\n",
    "    \n",
    "    print(\"Recording started...\")\n",
    "\n",
    "    if TEST_MODE:\n",
    "        process = Process(target=play_test_audio)\n",
    "        process.start()\n",
    "\n",
    "    output_file = wave.open(OUTPUT_FILENAME, \"wb\")\n",
    "    output_file.setnchannels(RECORD_CHANNELS)\n",
    "    output_file.setsampwidth(recoder.get_sample_size(RECORD_FORMAT))\n",
    "    output_file.setframerate(RECORD_RATE)\n",
    "    \n",
    "    while not params['interrupted']:\n",
    "        read = [stream.read(RECORD_CHUNK) for _ in range(FRAME_LENGTH)]\n",
    "        frame = b\"\".join(read)\n",
    "        output_file.writeframes(frame)\n",
    "        params['duration'] += len(read) / RECORD_RATE * RECORD_CHUNK\n",
    "\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    output_file.close()\n",
    "    if TEST_MODE:\n",
    "        process.terminate()\n",
    "    print(\"Recording stopped.\")"
   ],
   "id": "64218048f65cd5d6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Release Test",
   "id": "d680b17de3840a1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from stalk_models import llama3, whisper, audio, resnet152, system_prompt\n",
    "from stalk_streamer import record_audio, CACHE_FOLDER, OUTPUT_FILENAME\n",
    "\n",
    "from multiprocessing import Process, Manager\n",
    "from time import sleep\n",
    "import os\n",
    "import gc\n",
    "\n",
    "import torch\n",
    "import torchaudio\n",
    "from pyannote.core import Segment"
   ],
   "id": "1b2bc94e4d370b5a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "speaker1 = \"민서\", \"./SpeakerDiarization/sample_conversation/real/sentence_F.wav\"\n",
    "speaker2 = \"연우\", \"./SpeakerDiarization/sample_conversation/real/sentence_M.wav\"\n",
    "resnet152.register(*speaker1)\n",
    "resnet152.register(*speaker2)"
   ],
   "id": "ad801da944078508",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "user_prompt = f\"Based on the conversations between {speaker1[0]} and {speaker2[0]}, on be half of {speaker2[0]}, do recommend a new topic sentence related the current situation or their personal interests.\"",
   "id": "e19574a60a4fc738",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "manager = Manager()\n",
    "RECORD_PARAMS = manager.dict(interrupted=False, duration=0.0)\n",
    "\n",
    "record_thread = Process(target=record_audio, kwargs=dict(params=RECORD_PARAMS))\n",
    "record_thread.start()\n",
    "\n",
    "start_offset = 0.0\n",
    "temp_file = os.path.join(CACHE_FOLDER, \"temp.wav\")\n",
    "error_count = 0\n",
    "\n",
    "try:\n",
    "    while not RECORD_PARAMS['duration']:\n",
    "        sleep(0.001)  # Wait until the recording starts\n",
    "    \n",
    "    while True:\n",
    "        audio_range = Segment(start_offset, RECORD_PARAMS['duration'])\n",
    "        print(\"Transcribing audio...\", audio_range)\n",
    "        torchaudio.save(temp_file, *audio.crop(OUTPUT_FILENAME, audio_range))\n",
    "        \n",
    "        segments, info = whisper(temp_file, beam_size=5, word_timestamps=False)\n",
    "        #print(\"Transcription finished.\")\n",
    "        segments = iter(segments)\n",
    "\n",
    "        for segment in segments:\n",
    "            try:\n",
    "                crop_range = (start_offset + segment.start, start_offset + segment.end)\n",
    "                portion = audio.crop(OUTPUT_FILENAME, Segment(crop_range[0], crop_range[1]))\n",
    "                torchaudio.save(os.path.join(CACHE_FOLDER, f\"{crop_range[0]}.partial.wav\"), *portion)\n",
    "                \n",
    "                speaker = resnet152(*portion)\n",
    "\n",
    "                print(f\"\\r{crop_range} -> [{speaker['name']}] {segment.text.strip()}\", end=\"\", flush=True)\n",
    "                #ChatHistory.add_messages(speaker['name'], segment.text.strip())\n",
    "                \n",
    "                del portion, speaker\n",
    "                torch.cuda.empty_cache()\n",
    "    \n",
    "                if start_offset != crop_range[0]:\n",
    "                    start_offset = crop_range[0]\n",
    "                    print()\n",
    "            except:\n",
    "                error_count += 1\n",
    "                continue\n",
    "\n",
    "        gc.collect()\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Recording stopped by user\")\n",
    "finally:\n",
    "    RECORD_PARAMS['interrupted'] = True\n",
    "    record_thread.join()\n",
    "    print(\"Error count:\", error_count)\n",
    "    manager.close()"
   ],
   "id": "b5046c9735023f32",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "recoder.terminate()\n",
    "print(\"Recording finished.\")"
   ],
   "id": "9e79e0983cbbc95",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for message in ChatHistory.messages:\n",
    "    print(f\"[{message['role']}] {message['content']}\")"
   ],
   "id": "94cae5aae65261c3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for chunk in llama3(system_prompt, user_prompt):\n",
    "    print(token_stream(chunk), end=\"\", flush=True)\n",
    "print()"
   ],
   "id": "a3c48d7b0bdbd80",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "76fba3854403ce37",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
