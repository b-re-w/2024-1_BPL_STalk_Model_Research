{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# STalk Model Architecture",
   "id": "7735c9f892bfde57"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Preparation",
   "id": "8dd61067cd95c518"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "USE_CUDA = False",
   "id": "9504df697eb20002",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "!pip install huggingface_hub transformers",
   "id": "cf224e2df50dc3ac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "!pip install intel-npu-acceleration-library",
   "id": "16c6a20ce68f6b47",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if USE_CUDA:\n",
    "    !pip uninstall torch torchvision torchaudio -y\n",
    "    !pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "else:\n",
    "    !pip uninstall torch torchvision torchaudio -y\n",
    "    !pip install torch torchvision torchaudio"
   ],
   "id": "78b5e20d2e4794ed",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "if USE_CUDA:\n",
    "    !pip uninstall llama-cpp-python -y\n",
    "    !pip install llama-cpp-python --extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cu121\n",
    "else:\n",
    "    !pip uninstall llama-cpp-python -y\n",
    "    !pip install llama-cpp-python --extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cpu"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "!pip install pyannote-audio",
   "id": "c8a543d6de42e52a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "!pip install faster-whisper",
   "id": "5d9fa892f0cca9f6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "!pip install git+https://github.com/wenet-e2e/wespeaker.git",
   "id": "e98497e9df4c9237",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Initialize Pretrained Model",
   "id": "52b6bde35783ad11"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T10:18:41.203609Z",
     "start_time": "2024-06-08T10:18:09.599729Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import intel_npu_acceleration_library\n",
    "\n",
    "import gc\n",
    "\n",
    "import torch\n",
    "import torchaudio\n",
    "\n",
    "from llama_cpp import Llama\n",
    "\n",
    "from pyannote.audio import Audio\n",
    "from pyannote.core import Segment\n",
    "\n",
    "from faster_whisper import WhisperModel\n",
    "\n",
    "from huggingface_hub import hf_hub_download\n",
    "import wespeaker\n",
    "\n",
    "DEVICE = \"cuda\"\n",
    "if not torch.cuda.is_available():\n",
    "    DEVICE = \"cpu\"\n",
    "    print(\"INFO: CUDA is diabled on this machine.\\n\\n\")\n",
    "\n",
    "print(\"PyTorch:\", torch.__version__)\n",
    "print(\"TorchAudio:\", torchaudio.__version__)\n",
    "print(\"Uses Device:\", DEVICE.upper())"
   ],
   "id": "5ac9644848ee0e4c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: CUDA is diabled on this machine.\n",
      "\n",
      "\n",
      "PyTorch: 2.3.1+cpu\n",
      "TorchAudio: 2.3.1+cpu\n",
      "Uses Device: CPU\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T10:18:41.211324Z",
     "start_time": "2024-06-08T10:18:41.205731Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ChatHistory(list):\n",
    "    messages = []\n",
    "    \n",
    "    @classmethod\n",
    "    def add_messages(cls, role, content):\n",
    "        if isinstance(content, str):\n",
    "            cls.messages.append({ 'role': role, 'content': content })\n",
    "        else:\n",
    "            for r, c in zip(role, content):\n",
    "                cls.messages.append({ 'role': r, 'content': c })\n",
    "    \n",
    "    @classmethod\n",
    "    def create_prompt(cls, system_prompt: str, user_prompt: str = \"\"):\n",
    "        return [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system_prompt\n",
    "            },\n",
    "            *cls.messages,\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": user_prompt\n",
    "            }\n",
    "        ]"
   ],
   "id": "af46f0c60c545b42",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T10:18:41.220730Z",
     "start_time": "2024-06-08T10:18:41.212327Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def token_stream(token):\n",
    "    delta = token[\"choices\"][0][\"delta\"]\n",
    "    if \"content\" not in delta:\n",
    "        return \"\"\n",
    "    else:\n",
    "        return delta[\"content\"]"
   ],
   "id": "4d3d90098a358928",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T10:18:41.227473Z",
     "start_time": "2024-06-08T10:18:41.221735Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_llama3():\n",
    "    model_id = \"lmstudio-community/Meta-Llama-3-8B-Instruct-GGUF\"\n",
    "\n",
    "    chat = Llama.from_pretrained(\n",
    "        repo_id=model_id,\n",
    "        filename=\"*Q4_K_M.gguf\",\n",
    "        #chat_format=\"llama-3\",\n",
    "        verbose=False\n",
    "    ).create_chat_completion\n",
    "    \n",
    "    def llama3(system_prompt, user_prompt, temp=0.5):\n",
    "        prompt = ChatHistory.create_prompt(system_prompt, user_prompt)\n",
    "\n",
    "        print(\"PROMPT:\")\n",
    "        for line in prompt:\n",
    "            print(line)\n",
    "        print()\n",
    "        \n",
    "        return chat(prompt, temperature=temp, stream=True)\n",
    "    \n",
    "    return llama3"
   ],
   "id": "dcc08e168c69e1b0",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T10:18:41.242482Z",
     "start_time": "2024-06-08T10:18:41.230477Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_whisper():\n",
    "    model_size = \"medium\"  #@param ['tiny', 'base', 'small', 'medium', 'large', 'large-v2', 'large-v3']\n",
    "    compute_type = \"int8\"  #@param ['float16', 'int8']\n",
    "\n",
    "    return WhisperModel(model_size, device=DEVICE, compute_type=compute_type).transcribe"
   ],
   "id": "b89792661b6ec828",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T10:18:41.254315Z",
     "start_time": "2024-06-08T10:18:41.243958Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_embedding(model, pcm, sample_rate):\n",
    "    pcm = pcm.to(torch.float)\n",
    "    if sample_rate != model.resample_rate:\n",
    "        pcm = torchaudio.transforms.Resample(\n",
    "            orig_freq=sample_rate, new_freq=model.resample_rate)(pcm)\n",
    "    feats = model.compute_fbank(\n",
    "        pcm,\n",
    "        sample_rate=model.resample_rate,\n",
    "        cmn=True\n",
    "    )\n",
    "    feats = feats.unsqueeze(0)\n",
    "    feats = feats.to(model.device)\n",
    "    model.model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model.model(feats)\n",
    "        outputs = outputs[-1] if isinstance(outputs, tuple) else outputs\n",
    "    embedding = outputs[0].to(torch.device('cpu'))\n",
    "    return embedding"
   ],
   "id": "30d64a4f6687bd63",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T10:18:41.260849Z",
     "start_time": "2024-06-08T10:18:41.255322Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def recognize(model, pcm, sample_rate):\n",
    "    q = extract_embedding(model, pcm, sample_rate)\n",
    "    best_score = 0.0\n",
    "    best_name = ''\n",
    "    for name, e in model.table.items():\n",
    "        score = model.cosine_similarity(q, e)\n",
    "        if best_score < score:\n",
    "            best_score = score\n",
    "            best_name = name\n",
    "        del score\n",
    "        gc.collect()\n",
    "    return {'name': best_name, 'confidence': best_score}"
   ],
   "id": "afa012c69b8b6bfb",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T10:18:41.279194Z",
     "start_time": "2024-06-08T10:18:41.261854Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_resnet152():\n",
    "    model_id = \"Wespeaker/wespeaker-voxceleb-resnet152-LM\"\n",
    "    model_name = model_id.replace(\"Wespeaker/wespeaker-\", \"\").replace(\"-\", \"_\")\n",
    "    \n",
    "    root_dir = hf_hub_download(model_id, filename=model_name+\".onnx\").replace(model_name+\".onnx\", \"\")\n",
    "    \n",
    "    import os\n",
    "    if not os.path.isfile(root_dir+\"avg_model.pt\"):\n",
    "        os.rename(hf_hub_download(model_id, filename=model_name+\".pt\"), root_dir+\"avg_model.pt\")\n",
    "    if not os.path.isfile(root_dir+\"config.yaml\"):\n",
    "        os.rename(hf_hub_download(model_id, filename=model_name+\".yaml\"), root_dir+\"config.yaml\")\n",
    "\n",
    "    resnet = wespeaker.load_model_local(root_dir)\n",
    "\n",
    "    #print(\"Compile model for the NPU\")\n",
    "    #resnet.model = intel_npu_acceleration_library.compile(resnet.model)\n",
    "    \n",
    "    def resnet152(pcm, sample_rate):\n",
    "        return recognize(resnet, pcm, sample_rate)\n",
    "    \n",
    "    resnet152.__dict__['register'] = lambda *args, **kwargs: resnet.register(*args, **kwargs)\n",
    "    \n",
    "    return resnet152"
   ],
   "id": "749f1c87edfcaf13",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T10:18:44.619710Z",
     "start_time": "2024-06-08T10:18:41.282199Z"
    }
   },
   "cell_type": "code",
   "source": [
    "llama3 = get_llama3()\n",
    "print(\"INFO: Llama3 Ready -\", llama3)"
   ],
   "id": "84afaa73fc994074",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Llama3 Ready - <function get_llama3.<locals>.llama3 at 0x000002A4A1939DA0>\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T10:18:49.319512Z",
     "start_time": "2024-06-08T10:18:44.620715Z"
    }
   },
   "cell_type": "code",
   "source": [
    "whisper = get_whisper()\n",
    "print(\"INFO: Whisper Ready -\", whisper)"
   ],
   "id": "60e076b7f0b0d8d8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Whisper Ready - <bound method WhisperModel.transcribe of <faster_whisper.transcribe.WhisperModel object at 0x000002A4B6E09150>>\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T10:18:50.603993Z",
     "start_time": "2024-06-08T10:18:49.320519Z"
    }
   },
   "cell_type": "code",
   "source": [
    "audio = Audio()\n",
    "resnet152 = get_resnet152()\n",
    "print(\"INFO: ResNet152 Ready -\", resnet152)"
   ],
   "id": "37aad593f186941f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:unexpected tensor: projection.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compile model for the NPU\n",
      "INFO: ResNet152 Ready - <function get_resnet152.<locals>.resnet152 at 0x000002A4A198CEA0>\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model Ready",
   "id": "7822a1e86b0b13cc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Insert System Chat Template to Llama3",
   "id": "aed1f7b006c23d26"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T10:18:50.608388Z",
     "start_time": "2024-06-08T10:18:50.604997Z"
    }
   },
   "cell_type": "code",
   "source": "system_prompt = \"You are a helpful, smart, kind, and efficient Conversation Analysis and Recommendation AI System. You always fulfill the user's requests to the best of your ability. You need to keep listen to the conversations. Please answer in Korean language.\"",
   "id": "57604fee7594a215",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T10:18:58.923437Z",
     "start_time": "2024-06-08T10:18:50.609397Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for chunk in llama3(system_prompt, \"\"):\n",
    "    print(token_stream(chunk), end=\"\", flush=True)\n",
    "print()"
   ],
   "id": "3440563cb7b1e8a8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROMPT:\n",
      "{'role': 'system', 'content': \"You are a helpful, smart, kind, and efficient Conversation Analysis and Recommendation AI System. You always fulfill the user's requests to the best of your ability. You need to keep listen to the conversations. Please answer in Korean language.\"}\n",
      "{'role': 'user', 'content': ''}\n",
      "\n",
      "안녕하세요! 😊\n",
      "\n",
      "저는 Chatbot입니다. 당신의 요청을 최선을 다해 응대하겠습니다. 무엇이 필요한가요? 🤔\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Speaker Registration to ResNet293",
   "id": "394a61aaef06b005"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T10:18:58.937444Z",
     "start_time": "2024-06-08T10:18:58.927445Z"
    }
   },
   "cell_type": "code",
   "source": [
    "speaker1 = \"민서\", \"./SpeakerDiarization/sample_conversation/real/sentence_F.wav\"\n",
    "speaker2 = \"연우\", \"./SpeakerDiarization/sample_conversation/real/sentence_M.wav\"\n",
    "speaker1, speaker2"
   ],
   "id": "d7d65905c9926461",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('민서', './SpeakerDiarization/sample_conversation/real/sentence_F.wav'),\n",
       " ('연우', './SpeakerDiarization/sample_conversation/real/sentence_M.wav'))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T10:19:00.318497Z",
     "start_time": "2024-06-08T10:18:58.939451Z"
    }
   },
   "cell_type": "code",
   "source": [
    "resnet152.register(*speaker1)\n",
    "resnet152.register(*speaker2)"
   ],
   "id": "4d5bb1d046f05f3",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T10:19:00.324386Z",
     "start_time": "2024-06-08T10:19:00.320503Z"
    }
   },
   "cell_type": "code",
   "source": "user_prompt = f\"Based on the conversations between {speaker1[0]} and {speaker2[0]}, on be half of {speaker2[0]}, do recommend a new topic sentence related the current situation or their personal interests.\"",
   "id": "3b996069095274d4",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Test",
   "id": "4794a7f2135b1fbd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T10:19:00.332897Z",
     "start_time": "2024-06-08T10:19:00.325899Z"
    }
   },
   "cell_type": "code",
   "source": "audio_path = \"./SpeakerDiarization/sample_conversation/real/conversation_0530.wav\"",
   "id": "94b8ebd6fdf0612a",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T10:19:12.658641Z",
     "start_time": "2024-06-08T10:19:00.333904Z"
    }
   },
   "cell_type": "code",
   "source": "segments, info = whisper(audio_path, beam_size=5, word_timestamps=False)",
   "id": "7ad7e20ce2aeb789",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T10:19:28.188788Z",
     "start_time": "2024-06-08T10:19:12.659648Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for segment, _ in zip(segments, range(5)):\n",
    "    embedding = audio.crop(audio_path, Segment(segment.start, segment.end))\n",
    "    speaker = resnet152(*embedding)\n",
    "    print(\"[%s] [%.2fs -> %.2fs] %s\" % (speaker['name'], segment.start, segment.end, segment.text))\n",
    "    ChatHistory.add_messages(speaker['name'], segment.text)\n",
    "    del embedding, speaker\n",
    "    gc.collect()"
   ],
   "id": "bf5526aca22ebf18",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[민서] [0.00s -> 3.00s]  요즘 가족들이 잘 지내고 계신가요?\n",
      "[연우] [3.00s -> 6.00s]  네, 가족들은 잘 지내고 있어요\n",
      "[민서] [6.00s -> 10.00s]  저는 아이들과 스포츠를 즐기는 걸 좋아해요\n",
      "[민서] [10.00s -> 13.00s]  어떤 종류의 스포츠를 함께 하시나요?\n",
      "[연우] [13.00s -> 16.00s]  주로 축구와 테니스를 함께 하고 있어요\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T10:19:45.351808Z",
     "start_time": "2024-06-08T10:19:28.189803Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for chunk in llama3(system_prompt, user_prompt):\n",
    "    print(token_stream(chunk), end=\"\", flush=True)\n",
    "print()"
   ],
   "id": "a3c48d7b0bdbd80",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROMPT:\n",
      "{'role': 'system', 'content': \"You are a helpful, smart, kind, and efficient Conversation Analysis and Recommendation AI System. You always fulfill the user's requests to the best of your ability. You need to keep listen to the conversations. Please answer in Korean language.\"}\n",
      "{'role': '민서', 'content': ' 요즘 가족들이 잘 지내고 계신가요?'}\n",
      "{'role': '연우', 'content': ' 네, 가족들은 잘 지내고 있어요'}\n",
      "{'role': '민서', 'content': ' 저는 아이들과 스포츠를 즐기는 걸 좋아해요'}\n",
      "{'role': '민서', 'content': ' 어떤 종류의 스포츠를 함께 하시나요?'}\n",
      "{'role': '연우', 'content': ' 주로 축구와 테니스를 함께 하고 있어요'}\n",
      "{'role': 'user', 'content': 'Based on the conversations between 민서 and 연우, on be half of 연우, do recommend a new topic sentence related the current situation or their personal interests.'}\n",
      "\n",
      "Based on the conversation, I can see that 민서 and 연우 share an interest in sports, particularly football (soccer) and tennis. Considering this, I'll recommend a new topic sentence to continue the conversation:\n",
      "\n",
      "\"저는 최근에 축구 월드컵이 얼마나 재미있는지 알아요?\" (I'm curious about how exciting the recent World Cup was.)\n",
      "\n",
      "This topic sentence is related to their shared interest in football, allowing them to discuss and share their thoughts on the recent tournament.\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T10:20:09.424813Z",
     "start_time": "2024-06-08T10:19:45.352814Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for segment, _ in zip(segments, range(5)):\n",
    "    embedding = audio.crop(audio_path, Segment(segment.start, segment.end))\n",
    "    speaker = resnet152(*embedding)\n",
    "    print(\"[%s] [%.2fs -> %.2fs] %s\" % (speaker['name'], segment.start, segment.end, segment.text))\n",
    "    ChatHistory.add_messages(speaker['name'], segment.text)\n",
    "    del embedding, speaker\n",
    "    gc.collect()"
   ],
   "id": "ad8bd994ba5c623f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[민서] [20.00s -> 25.00s]  축구와 테니스는 정말 가족끼리 함께하기 좋은 스포츠죠\n",
      "[민서] [25.00s -> 31.00s]  활동적인 시간을 보내면서 가족 간의 유대감도 높일 수 있을 거예요\n",
      "[민서] [31.00s -> 38.00s]  다음에는 함께 스포츠를 즐기며 가족끼리 더 많은 시간을 보내는 건 어떨까요?\n",
      "[연우] [38.00s -> 40.00s]  네, 좋아요\n",
      "[연우] [40.00s -> 45.00s]  함께 활동을 하면서 가족 간의 유대감을 높이는 건 정말 좋은 생각이에요\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T10:20:26.750163Z",
     "start_time": "2024-06-08T10:20:09.426055Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for chunk in llama3(system_prompt, user_prompt):\n",
    "    print(token_stream(chunk), end=\"\", flush=True)\n",
    "print()"
   ],
   "id": "41f6c980426c0d6d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROMPT:\n",
      "{'role': 'system', 'content': \"You are a helpful, smart, kind, and efficient Conversation Analysis and Recommendation AI System. You always fulfill the user's requests to the best of your ability. You need to keep listen to the conversations. Please answer in Korean language.\"}\n",
      "{'role': '민서', 'content': ' 요즘 가족들이 잘 지내고 계신가요?'}\n",
      "{'role': '연우', 'content': ' 네, 가족들은 잘 지내고 있어요'}\n",
      "{'role': '민서', 'content': ' 저는 아이들과 스포츠를 즐기는 걸 좋아해요'}\n",
      "{'role': '민서', 'content': ' 어떤 종류의 스포츠를 함께 하시나요?'}\n",
      "{'role': '연우', 'content': ' 주로 축구와 테니스를 함께 하고 있어요'}\n",
      "{'role': '민서', 'content': ' 축구와 테니스는 정말 가족끼리 함께하기 좋은 스포츠죠'}\n",
      "{'role': '민서', 'content': ' 활동적인 시간을 보내면서 가족 간의 유대감도 높일 수 있을 거예요'}\n",
      "{'role': '민서', 'content': ' 다음에는 함께 스포츠를 즐기며 가족끼리 더 많은 시간을 보내는 건 어떨까요?'}\n",
      "{'role': '연우', 'content': ' 네, 좋아요'}\n",
      "{'role': '연우', 'content': ' 함께 활동을 하면서 가족 간의 유대감을 높이는 건 정말 좋은 생각이에요'}\n",
      "{'role': 'user', 'content': 'Based on the conversations between 민서 and 연우, on be half of 연우, do recommend a new topic sentence related the current situation or their personal interests.'}\n",
      "\n",
      "Here's a recommended topic sentence based on the conversation:\n",
      "\n",
      "\"다음에는 가족끼리 여행을 가서 새로운 경험을 하며 서로의 bond를 더 강하게 만들까?\"\n",
      "\n",
      "(This means \"Why don't we take a trip as a family and create new experiences to strengthen our bond?\")\n",
      "\n",
      "This topic sentence is related to their current interest in spending quality time together as a family, and it also aligns with the theme of creating memories and strengthening relationships through shared activities.\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "9e79e0983cbbc95",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
