{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# STalk Model Architecture",
   "id": "7735c9f892bfde57"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Preparation",
   "id": "8dd61067cd95c518"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "USE_CUDA = False",
   "id": "9504df697eb20002",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "!pip install huggingface_hub transformers",
   "id": "cf224e2df50dc3ac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "!pip install intel-npu-acceleration-library",
   "id": "16c6a20ce68f6b47",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if USE_CUDA:\n",
    "    !pip uninstall torch torchvision torchaudio -y\n",
    "    !pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "else:\n",
    "    !pip uninstall torch torchvision torchaudio -y\n",
    "    !pip install torch torchvision torchaudio"
   ],
   "id": "78b5e20d2e4794ed",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "if USE_CUDA:\n",
    "    !pip uninstall llama-cpp-python -y\n",
    "    !pip install llama-cpp-python --extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cu121\n",
    "else:\n",
    "    !pip uninstall llama-cpp-python -y\n",
    "    !pip install llama-cpp-python --extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cpu"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "!pip install pyannote-audio",
   "id": "c8a543d6de42e52a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "!pip install faster-whisper",
   "id": "5d9fa892f0cca9f6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "!pip install git+https://github.com/wenet-e2e/wespeaker.git",
   "id": "e98497e9df4c9237",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "!pip install pyaudio",
   "id": "aee2deb6480d288b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Initialize Pretrained Model",
   "id": "52b6bde35783ad11"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T11:31:44.248895Z",
     "start_time": "2024-06-09T11:31:33.176284Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import intel_npu_acceleration_library\n",
    "\n",
    "import gc\n",
    "\n",
    "import wave\n",
    "import pyaudio\n",
    "\n",
    "import torch\n",
    "import torchaudio\n",
    "\n",
    "from llama_cpp import Llama\n",
    "\n",
    "from pyannote.audio import Audio\n",
    "from pyannote.core import Segment\n",
    "\n",
    "from faster_whisper import WhisperModel\n",
    "\n",
    "from huggingface_hub import hf_hub_download\n",
    "import wespeaker\n",
    "\n",
    "DEVICE = \"cuda\"\n",
    "if not torch.cuda.is_available():\n",
    "    DEVICE = \"cpu\"\n",
    "    print(\"INFO: CUDA is diabled on this machine.\\n\\n\")\n",
    "\n",
    "print(\"PyTorch:\", torch.__version__)\n",
    "print(\"TorchAudio:\", torchaudio.__version__)\n",
    "print(\"Uses Device:\", DEVICE.upper())"
   ],
   "id": "5ac9644848ee0e4c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: CUDA is diabled on this machine.\n",
      "\n",
      "\n",
      "PyTorch: 2.3.1+cpu\n",
      "TorchAudio: 2.3.1+cpu\n",
      "Uses Device: CPU\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T11:31:44.255202Z",
     "start_time": "2024-06-09T11:31:44.249901Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ChatHistory(list):\n",
    "    messages = []\n",
    "    \n",
    "    @classmethod\n",
    "    def add_messages(cls, role, content):\n",
    "        if isinstance(content, str):\n",
    "            cls.messages.append({ 'role': role, 'content': content })\n",
    "        else:\n",
    "            for r, c in zip(role, content):\n",
    "                cls.messages.append({ 'role': r, 'content': c })\n",
    "    \n",
    "    @classmethod\n",
    "    def create_prompt(cls, system_prompt: str, user_prompt: str = \"\"):\n",
    "        return [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system_prompt\n",
    "            },\n",
    "            *cls.messages,\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": user_prompt\n",
    "            }\n",
    "        ]"
   ],
   "id": "af46f0c60c545b42",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T11:31:44.271160Z",
     "start_time": "2024-06-09T11:31:44.256209Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def token_stream(token):\n",
    "    delta = token[\"choices\"][0][\"delta\"]\n",
    "    if \"content\" not in delta:\n",
    "        return \"\"\n",
    "    else:\n",
    "        return delta[\"content\"]"
   ],
   "id": "4d3d90098a358928",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T11:31:44.277727Z",
     "start_time": "2024-06-09T11:31:44.271684Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_llama3():\n",
    "    model_id = \"lmstudio-community/Meta-Llama-3-8B-Instruct-GGUF\"\n",
    "\n",
    "    chat = Llama.from_pretrained(\n",
    "        repo_id=model_id,\n",
    "        filename=\"*Q4_K_M.gguf\",\n",
    "        #chat_format=\"llama-3\",\n",
    "        verbose=False\n",
    "    ).create_chat_completion\n",
    "    \n",
    "    def llama3(system_prompt, user_prompt, temp=0.5, show_prompt=False):\n",
    "        prompt = ChatHistory.create_prompt(system_prompt, user_prompt)\n",
    "\n",
    "        if show_prompt:\n",
    "            print(\"PROMPT:\")\n",
    "            for line in prompt:\n",
    "                print(line)\n",
    "            print()\n",
    "        \n",
    "        return chat(prompt, temperature=temp, stream=True)\n",
    "    \n",
    "    return llama3"
   ],
   "id": "dcc08e168c69e1b0",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T11:31:44.284045Z",
     "start_time": "2024-06-09T11:31:44.278733Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_whisper():\n",
    "    model_size = \"medium\"  #@param ['tiny', 'base', 'small', 'medium', 'large', 'large-v2', 'large-v3']\n",
    "    compute_type = \"int8\"  #@param ['float16', 'int8']\n",
    "\n",
    "    return WhisperModel(model_size, device=DEVICE, compute_type=compute_type).transcribe"
   ],
   "id": "b89792661b6ec828",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T11:31:44.290819Z",
     "start_time": "2024-06-09T11:31:44.285648Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_embedding(model, pcm, sample_rate):\n",
    "    pcm = pcm.to(torch.float)\n",
    "    if sample_rate != model.resample_rate:\n",
    "        pcm = torchaudio.transforms.Resample(\n",
    "            orig_freq=sample_rate, new_freq=model.resample_rate)(pcm)\n",
    "    feats = model.compute_fbank(\n",
    "        pcm,\n",
    "        sample_rate=model.resample_rate,\n",
    "        cmn=True\n",
    "    )\n",
    "    feats = feats.unsqueeze(0)\n",
    "    feats = feats.to(model.device)\n",
    "    model.model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model.model(feats)\n",
    "        outputs = outputs[-1] if isinstance(outputs, tuple) else outputs\n",
    "    embedding = outputs[0].to(torch.device('cpu'))\n",
    "    return embedding"
   ],
   "id": "30d64a4f6687bd63",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T11:31:44.296100Z",
     "start_time": "2024-06-09T11:31:44.291825Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def recognize(model, pcm, sample_rate):\n",
    "    q = extract_embedding(model, pcm, sample_rate)\n",
    "    best_score = 0.0\n",
    "    best_name = ''\n",
    "    for name, e in model.table.items():\n",
    "        score = model.cosine_similarity(q, e)\n",
    "        if best_score < score:\n",
    "            best_score = score\n",
    "            best_name = name\n",
    "        del score\n",
    "        gc.collect()\n",
    "    return {'name': best_name, 'confidence': best_score}"
   ],
   "id": "afa012c69b8b6bfb",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T11:31:44.302626Z",
     "start_time": "2024-06-09T11:31:44.297106Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_resnet152():\n",
    "    model_id = \"Wespeaker/wespeaker-voxceleb-resnet152-LM\"\n",
    "    model_name = model_id.replace(\"Wespeaker/wespeaker-\", \"\").replace(\"-\", \"_\")\n",
    "    \n",
    "    root_dir = hf_hub_download(model_id, filename=model_name+\".onnx\").replace(model_name+\".onnx\", \"\")\n",
    "    \n",
    "    import os\n",
    "    if not os.path.isfile(root_dir+\"avg_model.pt\"):\n",
    "        os.rename(hf_hub_download(model_id, filename=model_name+\".pt\"), root_dir+\"avg_model.pt\")\n",
    "    if not os.path.isfile(root_dir+\"config.yaml\"):\n",
    "        os.rename(hf_hub_download(model_id, filename=model_name+\".yaml\"), root_dir+\"config.yaml\")\n",
    "\n",
    "    resnet = wespeaker.load_model_local(root_dir)\n",
    "\n",
    "    #print(\"Compile model for the NPU\")\n",
    "    #resnet.model = intel_npu_acceleration_library.compile(resnet.model)\n",
    "    \n",
    "    def resnet152(ado, sample_rate=None):\n",
    "        if isinstance(ado, str):\n",
    "            return resnet.recognize(ado)\n",
    "        else:\n",
    "            return recognize(resnet, ado, sample_rate)\n",
    "    \n",
    "    resnet152.__dict__['register'] = lambda *args, **kwargs: resnet.register(*args, **kwargs)\n",
    "    \n",
    "    return resnet152"
   ],
   "id": "749f1c87edfcaf13",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T11:31:46.260362Z",
     "start_time": "2024-06-09T11:31:44.303630Z"
    }
   },
   "cell_type": "code",
   "source": [
    "llama3 = get_llama3()\n",
    "print(\"INFO: Llama3 Ready -\", llama3)"
   ],
   "id": "84afaa73fc994074",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Llama3 Ready - <function get_llama3.<locals>.llama3 at 0x000001828EBAA3E0>\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T11:31:49.660903Z",
     "start_time": "2024-06-09T11:31:46.261368Z"
    }
   },
   "cell_type": "code",
   "source": [
    "whisper = get_whisper()\n",
    "print(\"INFO: Whisper Ready -\", whisper)"
   ],
   "id": "60e076b7f0b0d8d8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Whisper Ready - <bound method WhisperModel.transcribe of <faster_whisper.transcribe.WhisperModel object at 0x000001828EB17B10>>\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T11:31:50.123267Z",
     "start_time": "2024-06-09T11:31:49.661911Z"
    }
   },
   "cell_type": "code",
   "source": [
    "audio = Audio()\n",
    "resnet152 = get_resnet152()\n",
    "print(\"INFO: ResNet152 Ready -\", resnet152)"
   ],
   "id": "37aad593f186941f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:unexpected tensor: projection.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: ResNet152 Ready - <function get_resnet152.<locals>.resnet152 at 0x000001828EBAB060>\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model Ready",
   "id": "7822a1e86b0b13cc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Insert System Chat Template to Llama3",
   "id": "aed1f7b006c23d26"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T11:31:50.127645Z",
     "start_time": "2024-06-09T11:31:50.124272Z"
    }
   },
   "cell_type": "code",
   "source": "system_prompt = \"You are a helpful, smart, kind, and efficient Conversation Analysis and Recommendation AI System. You always fulfill the user's requests to the best of your ability. You need to keep listen to the conversations. Please answer in Korean language.\"",
   "id": "57604fee7594a215",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T11:32:01.140194Z",
     "start_time": "2024-06-09T11:31:50.130159Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for chunk in llama3(system_prompt, \"\"):\n",
    "    print(token_stream(chunk), end=\"\", flush=True)\n",
    "print()"
   ],
   "id": "3440563cb7b1e8a8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ˜Š\n",
      "\n",
      "ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” ì§€ëŠ¥í˜• ëŒ€í™” ë¶„ì„ ë° ì¶”ì²œ AI ì‹œìŠ¤í…œì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ìš”ì²­ì„ ìµœì„ ì„ ë‹¤í•´ ì¶©ì¡±í•©ë‹ˆë‹¤. ëŒ€í™”ë¥¼.listení•˜ê³  ë‹µë³€ì„ ì œê³µí•  ê²ƒì…ë‹ˆë‹¤. í•œêµ­ì–´ë¡œ ë‹µë³€ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤. ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”? ğŸ¤”\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Speaker Registration to ResNet293",
   "id": "394a61aaef06b005"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T11:32:01.149519Z",
     "start_time": "2024-06-09T11:32:01.143199Z"
    }
   },
   "cell_type": "code",
   "source": [
    "speaker1 = \"ë¯¼ì„œ\", \"./SpeakerDiarization/sample_conversation/real/sentence_F.wav\"\n",
    "speaker2 = \"ì—°ìš°\", \"./SpeakerDiarization/sample_conversation/real/sentence_M.wav\"\n",
    "speaker1, speaker2"
   ],
   "id": "d7d65905c9926461",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('ë¯¼ì„œ', './SpeakerDiarization/sample_conversation/real/sentence_F.wav'),\n",
       " ('ì—°ìš°', './SpeakerDiarization/sample_conversation/real/sentence_M.wav'))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T11:32:02.230622Z",
     "start_time": "2024-06-09T11:32:01.150526Z"
    }
   },
   "cell_type": "code",
   "source": [
    "resnet152.register(*speaker1)\n",
    "resnet152.register(*speaker2)"
   ],
   "id": "4d5bb1d046f05f3",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T11:32:02.236008Z",
     "start_time": "2024-06-09T11:32:02.232626Z"
    }
   },
   "cell_type": "code",
   "source": "user_prompt = f\"Based on the conversations between {speaker1[0]} and {speaker2[0]}, on be half of {speaker2[0]}, do recommend a new topic sentence related the current situation or their personal interests.\"",
   "id": "3b996069095274d4",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Test",
   "id": "4794a7f2135b1fbd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T11:32:02.252077Z",
     "start_time": "2024-06-09T11:32:02.236522Z"
    }
   },
   "cell_type": "code",
   "source": "TEST_MODE = False",
   "id": "bfd4170a9eb3cbec",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T11:32:02.472567Z",
     "start_time": "2024-06-09T11:32:02.253082Z"
    }
   },
   "cell_type": "code",
   "source": [
    "RECORD_FORMAT = pyaudio.paInt16\n",
    "RECORD_RATE = 44100\n",
    "RECORD_CHANNELS = 1\n",
    "RECORD_CHUNK = 1024\n",
    "recoder = pyaudio.PyAudio()"
   ],
   "id": "6f29cc187768259d",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T11:32:02.478339Z",
     "start_time": "2024-06-09T11:32:02.473573Z"
    }
   },
   "cell_type": "code",
   "source": [
    "RECORD_SECONDS = 5\n",
    "FRAME_LENGTH = int(RECORD_RATE / RECORD_CHUNK * RECORD_SECONDS)\n",
    "\n",
    "CACHE_FILENAME = \"./cache/cache.wav\"\n",
    "OUTPUT_FILENAME = \"conversation_output.wav\""
   ],
   "id": "a267362d9045abd5",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T11:32:02.485366Z",
     "start_time": "2024-06-09T11:32:02.479348Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from time import sleep\n",
    "\n",
    "def play_test_audio():\n",
    "    audio_path = \"./SpeakerDiarization/sample_conversation/real/conversation_0530_out.wav\"\n",
    "    test_file = wave.open(audio_path, \"rb\")\n",
    "\n",
    "    player = recoder.open(\n",
    "        format=recoder.get_format_from_width(test_file.getsampwidth()),\n",
    "        channels=test_file.getnchannels(),\n",
    "        rate=test_file.getframerate(),\n",
    "        output=True,\n",
    "        stream_callback=lambda _, frame_count, __, ___: (test_file.readframes(frame_count), pyaudio.paContinue)\n",
    "    )\n",
    "\n",
    "    player.start_stream()\n",
    "    print(\"Playing test audio...\")\n",
    "    \n",
    "    while player.is_active():\n",
    "        sleep(0.1)\n",
    "\n",
    "    player.stop_stream()\n",
    "    player.close()"
   ],
   "id": "7ce11f83da97573",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T11:32:02.493395Z",
     "start_time": "2024-06-09T11:32:02.487375Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from multiprocessing import Process\n",
    "\n",
    "RECORD_INTERRUPTED = False\n",
    "RECORDED_FRAMES = []\n",
    "\n",
    "def record_audio():\n",
    "    stream = recoder.open(\n",
    "        format=RECORD_FORMAT, channels=RECORD_CHANNELS,\n",
    "        rate=RECORD_RATE, input=True,\n",
    "        frames_per_buffer=RECORD_CHUNK\n",
    "    )\n",
    "    \n",
    "    print(\"Recording started...\")\n",
    "\n",
    "    if TEST_MODE:\n",
    "        process = Process(target=play_test_audio)\n",
    "        process.start()\n",
    "\n",
    "    output_file = wave.open(OUTPUT_FILENAME, \"wb\")\n",
    "    output_file.setnchannels(RECORD_CHANNELS)\n",
    "    output_file.setsampwidth(recoder.get_sample_size(RECORD_FORMAT))\n",
    "    output_file.setframerate(RECORD_RATE)\n",
    "    \n",
    "    while not RECORD_INTERRUPTED:\n",
    "        frame = b\"\".join([stream.read(RECORD_CHUNK) for _ in range(FRAME_LENGTH)])\n",
    "        output_file.writeframes(frame)\n",
    "        RECORDED_FRAMES.append(frame)\n",
    "\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    output_file.close()\n",
    "    if TEST_MODE:\n",
    "        process.terminate()\n",
    "    print(\"Recording stopped.\")"
   ],
   "id": "64218048f65cd5d6",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T11:35:06.205299Z",
     "start_time": "2024-06-09T11:32:07.668493Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from threading import Thread\n",
    "\n",
    "try:\n",
    "    RECORD_INTERRUPTED = False\n",
    "    RECORDED_FRAMES = []\n",
    "    \n",
    "    record_thread = Thread(target=record_audio)\n",
    "    record_thread.start()\n",
    "    \n",
    "    i = 0\n",
    "    last_frame = []\n",
    "    identical = True\n",
    "    \n",
    "    while True:\n",
    "        if not len(RECORDED_FRAMES):\n",
    "            continue\n",
    "        frame = RECORDED_FRAMES.pop(0)\n",
    "        \n",
    "        CACHE = CACHE_FILENAME.replace(\".wav\", f\"_{i}.wav\")\n",
    "        \n",
    "        cache_file = wave.open(CACHE, \"wb\")\n",
    "        cache_file.setnchannels(RECORD_CHANNELS)\n",
    "        cache_file.setsampwidth(recoder.get_sample_size(RECORD_FORMAT))\n",
    "        cache_file.setframerate(RECORD_RATE)\n",
    "        cache_file.writeframes(b\"\".join([*last_frame, frame]))\n",
    "\n",
    "        segments, info = whisper(CACHE, beam_size=5, word_timestamps=False)\n",
    "        print(\"Transcription finished.\")\n",
    "        segments = iter(segments)\n",
    "        \n",
    "        if not identical:\n",
    "            next(segments)\n",
    "            last_frame = [last_frame[-1]]\n",
    "        else:\n",
    "            ChatHistory.messages = ChatHistory.messages[:-1]\n",
    "\n",
    "        for index, segment in enumerate(segments):\n",
    "            try:\n",
    "                embedding = audio.crop(CACHE, Segment(segment.start, segment.end))\n",
    "            except:\n",
    "                embedding = (CACHE, )\n",
    "\n",
    "            print(f\"{i+1}-{index+1}\", (segment.start, segment.end), \"->\", end=\" \", flush=True)\n",
    "\n",
    "            speaker = resnet152(*embedding)\n",
    "            print(\"[%s] %s\" % (speaker['name'], segment.text.strip()))\n",
    "            ChatHistory.add_messages(speaker['name'], segment.text.strip())\n",
    "            \n",
    "            del embedding, speaker\n",
    "            \n",
    "            identical = index <= 1\n",
    "        \n",
    "        if identical:\n",
    "            last_frame = [b\"\".join([*last_frame, frame])]\n",
    "        else:\n",
    "            last_frame.append(frame)\n",
    "\n",
    "        del frame\n",
    "        gc.collect()\n",
    "        \n",
    "        i += 1\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Recording stopped by user\")\n",
    "finally:\n",
    "    RECORD_INTERRUPTED = True\n",
    "    record_thread.join()"
   ],
   "id": "b5046c9735023f32",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording started...\n",
      "Transcription finished.\n",
      "1-1 (0.0, 5.0) -> [ë¯¼ì„œ] ìš”ì¦˜ ê°€ì¡±ë“¤ì´ ì˜ ì§€ë‚´ê³  ê³„ì‹ ê°€ìš”?\n",
      "Transcription finished.\n",
      "2-1 (0.0, 4.4) -> [ë¯¼ì„œ] ìš”ì¦˜ ê°€ì¡±ë“¤ì´ ì˜ ì§€ë‚´ê³  ê³„ì‹ ê°€ìš”?\n",
      "2-2 (4.4, 7.36) -> [ì—°ìš°] ë„¤, ê°€ì¡±ë“¤ì€ ì˜ ì§€ë‚´ê³  ìˆì–´ìš”.\n",
      "2-3 (7.36, 10.4) -> [ë¯¼ì„œ] ì €ëŠ” ì•„ì´ë“¤ê³¼ ìŠ¤í¬ì¸ ë¥¼ ì¦ê¸°ëŠ” ê²ƒ ê°™ì•„ìš”.\n",
      "Transcription finished.\n",
      "Transcription finished.\n",
      "4-1 (2.5, 6.5) -> [ë¯¼ì„œ] ì €ëŠ” ì•„ì´ë“¤ê³¼ ìŠ¤í¬ì¸ ë¥¼ ì¦ê¸°ëŠ” ê±¸ ì¢‹ì•„í•´ìš”.\n",
      "4-2 (6.5, 9.5) -> [ë¯¼ì„œ] ì–´ë–¤ ì¢…ë¥˜ì˜ ìŠ¤í¬ì¸ ë¥¼ í•¨ê»˜ í•˜ì‹œë‚˜ìš”?\n",
      "4-3 (9.5, 11.9) -> [ì—°ìš°] ì¶•êµ¬ì™€ í…Œë‹ˆìŠ¤ë¥¼ í•¨ê»˜ í•˜ê³  ìˆì–´ìš”.\n",
      "4-4 (11.9, 15.0) -> [ë¯¼ì„œ] ì•„ì´ë“¤ì´ ì ê·¹ì ìœ¼ë¡œ ì°¸ì—¬í•˜ë©´ì„œ ì¦ê±°ìš´ ì‹œê°„ì„ ë³´ë‚´ìš”.\n",
      "Transcription finished.\n",
      "5-1 (4.48, 11.16) -> [ì—°ìš°] ì¶•êµ¬ì™€ í…Œë‹ˆìŠ¤ë¥¼ í•¨ê»˜ í•˜ê³  ìˆì–´ìš” ì•„ì´ë“¤ì´ ì ê·¹ì ìœ¼ë¡œ ì°¸ì—¬í•˜ë©´ì„œ ì¦ê±°ìš´ ì‹œê°„ì„ ë³´ë‚´ê³  ìˆì–´ìš”\n",
      "5-2 (11.16, 17.04) -> [ë¯¼ì„œ] ì¶•êµ¬ì™€ í…Œë‹ˆìŠ¤ëŠ” ì •ë§ ê°€ì¡±ë¼ë¦¬ í•¨ê»˜ í•˜ê¸° ì¢‹ì€ ìŠ¤í¬ì¸ \n",
      "Transcription finished.\n",
      "6-1 (0.0, 6.0) -> [ì—°ìš°] ì¶•êµ¬ì™€ í…Œë‹ˆìŠ¤ë¥¼ í•¨ê»˜í•˜ê³  ìˆì–´ìš”. ì•„ì´ë“¤ì´ ì ê·¹ì ìœ¼ë¡œ ì°¸ì—¬í•˜ë©´ì„œ ì¦ê±°ìš´ ì‹œê°„ì„ ë³´ë‚´ê³  ìˆì–´ìš”.\n",
      "6-2 (6.0, 15.0) -> [ë¯¼ì„œ] ì¶•êµ¬ì™€ í…Œë‹ˆìŠ¤ëŠ” ì •ë§ ê°€ì¡±ë¼ë¦¬ í•¨ê»˜í•˜ê¸° ì¢‹ì€ ìŠ¤í¬ì¸ ì£ . í™œë™ì ì¸ ì‹œê°„ì„ ë³´ë‚´ë©´ì„œ ê°€ì¡± ê°„ì˜ ìœ ëŒ€ê°ë„ ë†’ì¼ ìˆ˜ ìˆì–´ìš”.\n",
      "Transcription finished.\n",
      "7-1 (0.0, 2.0) -> [ì—°ìš°] ì¶•êµ¬ì™€ í…Œë‹ˆìŠ¤ë¥¼ í•¨ê»˜í•˜ê³  ìˆì–´ìš”.\n",
      "7-2 (2.0, 6.0) -> [ì—°ìš°] ì•„ì´ë“¤ì´ ì ê·¹ì ìœ¼ë¡œ ì°¸ì—¬í•˜ë©´ì„œ ì¦ê±°ìš´ ì‹œê°„ì„ ë³´ë‚´ê³  ìˆì–´ìš”.\n",
      "7-3 (6.0, 11.0) -> [ë¯¼ì„œ] ì¶•êµ¬ì™€ í…Œë‹ˆìŠ¤ëŠ” ì •ë§ ê°€ì¡±ë¼ë¦¬ í•¨ê»˜í•˜ê¸° ì¢‹ì€ ìŠ¤í¬ì¸ ì£ .\n",
      "7-4 (11.0, 17.0) -> [ë¯¼ì„œ] í™œë™ì ì¸ ì‹œê°„ì„ ë³´ë‚´ë©´ì„œ ê°€ì¡± ê°„ì˜ ìœ ëŒ€ê°ë„ ë†’ì¼ ìˆ˜ ìˆì„ ê±°ì˜ˆìš”.\n",
      "7-5 (17.0, 20.0) -> [ë¯¼ì„œ] ë‹¤ìŒì—ëŠ” í•¨ê»˜ ìŠ¤í”„ë¥¼ ì¦ê¸°ë©°\n",
      "Transcription finished.\n",
      "8-1 (6.2, 16.86) -> [ë¯¼ì„œ] ì¶•êµ¬ì™€ í…Œë‹ˆìŠ¤ëŠ” ì •ë§ ê°€ì¡±ë¼ë¦¬ í•¨ê»˜í•˜ê¸° ì¢‹ì€ ìŠ¤í¬ì¸ ì£ . í™œë™ì ì¸ ì‹œê°„ì„ ë³´ë‚´ë©´ì„œ ê°€ì¡± ê°„ì˜ ìœ ëŒ€ê°ë„ ë†’ì¼ ìˆ˜ ìˆì„ ê±°ì—ìš”.\n",
      "8-2 (16.86, 23.44) -> [ë¯¼ì„œ] ë‹¤ìŒì—ëŠ” í•¨ê»˜ ìŠ¤í¬ì¸ ë¥¼ ì¦ê¸°ë©° ê°€ì¡±ë¼ë¦¬ ë” ë§ì€ ì‹œê°„ì„ ë³´ë‚´ëŠ” ê±´ ì–´ë–¨ê¹Œìš”?\n",
      "8-3 (23.44, 26.240000000000002) -> [ë¯¼ì„œ] ë„¤ ì¢‹ì•„ìš”\n",
      "Transcription finished.\n",
      "Recording stopped by user\n",
      "Recording stopped.\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T11:35:09.930245Z",
     "start_time": "2024-06-09T11:35:09.925080Z"
    }
   },
   "cell_type": "code",
   "source": [
    "recoder.terminate()\n",
    "print(\"Recording finished.\")"
   ],
   "id": "9e79e0983cbbc95",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording finished.\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T11:35:10.623739Z",
     "start_time": "2024-06-09T11:35:10.620344Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for message in ChatHistory.messages:\n",
    "    print(f\"[{message['role']}] {message['content']}\")"
   ],
   "id": "94cae5aae65261c3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ë¯¼ì„œ] ìš”ì¦˜ ê°€ì¡±ë“¤ì´ ì˜ ì§€ë‚´ê³  ê³„ì‹ ê°€ìš”?\n",
      "[ì—°ìš°] ë„¤, ê°€ì¡±ë“¤ì€ ì˜ ì§€ë‚´ê³  ìˆì–´ìš”.\n",
      "[ë¯¼ì„œ] ì €ëŠ” ì•„ì´ë“¤ê³¼ ìŠ¤í¬ì¸ ë¥¼ ì¦ê¸°ëŠ” ê²ƒ ê°™ì•„ìš”.\n",
      "[ë¯¼ì„œ] ì €ëŠ” ì•„ì´ë“¤ê³¼ ìŠ¤í¬ì¸ ë¥¼ ì¦ê¸°ëŠ” ê±¸ ì¢‹ì•„í•´ìš”.\n",
      "[ë¯¼ì„œ] ì–´ë–¤ ì¢…ë¥˜ì˜ ìŠ¤í¬ì¸ ë¥¼ í•¨ê»˜ í•˜ì‹œë‚˜ìš”?\n",
      "[ì—°ìš°] ì¶•êµ¬ì™€ í…Œë‹ˆìŠ¤ë¥¼ í•¨ê»˜ í•˜ê³  ìˆì–´ìš”.\n",
      "[ë¯¼ì„œ] ì•„ì´ë“¤ì´ ì ê·¹ì ìœ¼ë¡œ ì°¸ì—¬í•˜ë©´ì„œ ì¦ê±°ìš´ ì‹œê°„ì„ ë³´ë‚´ìš”.\n",
      "[ì—°ìš°] ì¶•êµ¬ì™€ í…Œë‹ˆìŠ¤ë¥¼ í•¨ê»˜ í•˜ê³  ìˆì–´ìš” ì•„ì´ë“¤ì´ ì ê·¹ì ìœ¼ë¡œ ì°¸ì—¬í•˜ë©´ì„œ ì¦ê±°ìš´ ì‹œê°„ì„ ë³´ë‚´ê³  ìˆì–´ìš”\n",
      "[ì—°ìš°] ì¶•êµ¬ì™€ í…Œë‹ˆìŠ¤ë¥¼ í•¨ê»˜í•˜ê³  ìˆì–´ìš”. ì•„ì´ë“¤ì´ ì ê·¹ì ìœ¼ë¡œ ì°¸ì—¬í•˜ë©´ì„œ ì¦ê±°ìš´ ì‹œê°„ì„ ë³´ë‚´ê³  ìˆì–´ìš”.\n",
      "[ì—°ìš°] ì¶•êµ¬ì™€ í…Œë‹ˆìŠ¤ë¥¼ í•¨ê»˜í•˜ê³  ìˆì–´ìš”.\n",
      "[ì—°ìš°] ì•„ì´ë“¤ì´ ì ê·¹ì ìœ¼ë¡œ ì°¸ì—¬í•˜ë©´ì„œ ì¦ê±°ìš´ ì‹œê°„ì„ ë³´ë‚´ê³  ìˆì–´ìš”.\n",
      "[ë¯¼ì„œ] ì¶•êµ¬ì™€ í…Œë‹ˆìŠ¤ëŠ” ì •ë§ ê°€ì¡±ë¼ë¦¬ í•¨ê»˜í•˜ê¸° ì¢‹ì€ ìŠ¤í¬ì¸ ì£ .\n",
      "[ë¯¼ì„œ] í™œë™ì ì¸ ì‹œê°„ì„ ë³´ë‚´ë©´ì„œ ê°€ì¡± ê°„ì˜ ìœ ëŒ€ê°ë„ ë†’ì¼ ìˆ˜ ìˆì„ ê±°ì˜ˆìš”.\n",
      "[ë¯¼ì„œ] ë‹¤ìŒì—ëŠ” í•¨ê»˜ ìŠ¤í”„ë¥¼ ì¦ê¸°ë©°\n",
      "[ë¯¼ì„œ] ì¶•êµ¬ì™€ í…Œë‹ˆìŠ¤ëŠ” ì •ë§ ê°€ì¡±ë¼ë¦¬ í•¨ê»˜í•˜ê¸° ì¢‹ì€ ìŠ¤í¬ì¸ ì£ . í™œë™ì ì¸ ì‹œê°„ì„ ë³´ë‚´ë©´ì„œ ê°€ì¡± ê°„ì˜ ìœ ëŒ€ê°ë„ ë†’ì¼ ìˆ˜ ìˆì„ ê±°ì—ìš”.\n",
      "[ë¯¼ì„œ] ë‹¤ìŒì—ëŠ” í•¨ê»˜ ìŠ¤í¬ì¸ ë¥¼ ì¦ê¸°ë©° ê°€ì¡±ë¼ë¦¬ ë” ë§ì€ ì‹œê°„ì„ ë³´ë‚´ëŠ” ê±´ ì–´ë–¨ê¹Œìš”?\n",
      "[ë¯¼ì„œ] ë„¤ ì¢‹ì•„ìš”\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for chunk in llama3(system_prompt, user_prompt):\n",
    "    print(token_stream(chunk), end=\"\", flush=True)\n",
    "print()"
   ],
   "id": "a3c48d7b0bdbd80",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "76fba3854403ce37",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
