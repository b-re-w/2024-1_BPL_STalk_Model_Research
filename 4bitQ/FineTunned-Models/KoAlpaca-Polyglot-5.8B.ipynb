{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "!pip install transformers tokenizers accelerate safetensors"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import pipeline, AutoModelForCausalLM"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-11T06:22:35.925039Z",
     "start_time": "2024-04-11T06:22:32.124998Z"
    }
   },
   "id": "44f5311d6f763fbd",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Loading checkpoint shards:   0%|          | 0/13 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "911f1d08733a45678d8c27c912041d23"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "GPTNeoXForCausalLM(\n  (gpt_neox): GPTNeoXModel(\n    (embed_in): Embedding(30080, 4096)\n    (emb_dropout): Dropout(p=0.0, inplace=False)\n    (layers): ModuleList(\n      (0-27): 28 x GPTNeoXLayer(\n        (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n        (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n        (attention): GPTNeoXAttention(\n          (rotary_emb): GPTNeoXRotaryEmbedding()\n          (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)\n          (dense): Linear(in_features=4096, out_features=4096, bias=True)\n          (attention_dropout): Dropout(p=0.0, inplace=False)\n        )\n        (mlp): GPTNeoXMLP(\n          (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)\n          (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)\n          (act): GELUActivation()\n        )\n      )\n    )\n    (final_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n  )\n  (embed_out): Linear(in_features=4096, out_features=30080, bias=False)\n)"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL = 'beomi/KoAlpaca-Polyglot-5.8B'\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL,\n",
    "    torch_dtype=torch.float16,\n",
    "    low_cpu_mem_usage=True,\n",
    ").to(device=f\"cuda\", non_blocking=True)\n",
    "model.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-11T06:23:04.650575Z",
     "start_time": "2024-04-11T06:22:35.926045Z"
    }
   },
   "id": "7e934b8c7edeca19",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(\n",
    "    'text-generation',\n",
    "    model=model,\n",
    "    tokenizer=MODEL,\n",
    "    device=0\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-11T06:23:11.320807Z",
     "start_time": "2024-04-11T06:23:11.219617Z"
    }
   },
   "id": "49f836d5683ef9e5",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def ask(x, context='', is_input_full=False):\n",
    "    ans = pipe(\n",
    "        f\"### 질문: {x}\\n\\n### 맥락: {context}\\n\\n### 답변:\" if context else f\"### 질문: {x}\\n\\n### 답변:\",\n",
    "        do_sample=True,\n",
    "        max_new_tokens=512,\n",
    "        temperature=0.7,\n",
    "        top_p=0.9,\n",
    "        return_full_text=False,\n",
    "        eos_token_id=2,\n",
    "    )\n",
    "    print(ans[0]['generated_text'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-11T06:23:17.648904Z",
     "start_time": "2024-04-11T06:23:17.645486Z"
    }
   },
   "id": "ecbdb24200179f77",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "딥러닝은 인공신경망을 통해 더 복잡하고 많은 데이터를 처리하여 유용한 정보를 추출하는 머신러닝의 분야입니다. 이 기술은 컴퓨터가 데이터를 학습하고 패턴을 인식하며 예측하는 능력을 향상시켜 인공지능 분야에 널리 사용됩니다. 딥러닝은 선형 회귀, 분류, 군집화, 차원 축소 등 다양한 분야에서 활용됩니다. 예를 들어, 알파고와 같은 인공지능이 딥러닝 기법을 사용하여 구현되었습니다. 최근에는 딥러닝을 활용한 인공지능 기반 개인 비서 애플리케이션도 출시되고 있습니다. \n"
     ]
    }
   ],
   "source": [
    "ask(\"딥러닝이 뭐야?\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-11T06:28:13.835023Z",
     "start_time": "2024-04-11T06:23:35.960602Z"
    }
   },
   "id": "228e098549ea7bfb",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 자신에 대한 소개를 충분히 해 주세요. 자신의 경험과 더불어 얼굴, 이름, 고향, 취미 등의 정보를 공유해 주시면 좋습니다.\n",
      "2. 대화 주제를 추천해 주세요. 일상적인 대화에서는 자신이 관심있는 분야에 대해 이야기하는 것이 좋습니다. 그리고 자신이 상대방에 대해 미리 파악해두는 것이 좋습니다.\n",
      "3. 대화할 때는 말투와 톤을 조절하세요. 즐거운 분위기에서 대화를 하더라도, 긴장을 풀고 이야기하는 것이 중요합니다.\n",
      "4. 상대방의 눈을 바라보며 대화하세요. 시선을 내리깔거나, 딴 곳을 보는 행동은 자신감이 없어보이므로 주의해야 합니다.\n",
      "5. 상대방의 말을 경청하세요. 상대방의 말에 집중하고, 호응하는 것이 중요합니다.\n",
      "6. 대화할 때는 상호 간의 대화를 나누세요. 대화의 진행을 위해 가벼운 주제를 추천하는 것이 좋습니다.\n",
      "7. 자신의 이야기를 하면서도 상대방의 이야기를 존중하세요. 상대방의 이야기에 귀를 기울이고, 존중하는 마음을 가지는 것이 중요합니다.\n",
      "8. 자신의 성격 특성을 고려하세요. 자신이 사교적인지, 유머감각이 좋은지, 적극적인지, 수동적인지 등을 파악하여 대화할 때 적용하는 것이 좋습니다. \n"
     ]
    }
   ],
   "source": [
    "ask(\"소개팅 자리에서 어색하지 않게 대화하고 싶어 혹시 대화 주제를 추천해줄 수 있을까?\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-11T06:44:36.769610Z",
     "start_time": "2024-04-11T06:28:20.420125Z"
    }
   },
   "id": "46e7d487ee36730d",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "5274e0d0f80b05d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
