{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Llama3 Quantization\n",
    "\n",
    "[Llama3 Quantization](https://www.reddit.com/r/LocalLLaMA/comments/1cci5w6/quantizing_llama_3_8b_seems_more_harmful_compared/)\n",
    "[How Good Are Low-bit Quantized LLaMA3 Models?](\"https://arxiv.org/abs/2404.14047v1\")\n",
    "\n",
    "[llama-cpp-python](\"https://github.com/abetlen/llama-cpp-python\")"
   ],
   "id": "92596174f2f34fb1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-30T22:51:30.368875Z",
     "start_time": "2024-05-30T22:51:26.322689Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install llama-cpp-python --extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cu121",
   "id": "db55bfef1aa58740",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://abetlen.github.io/llama-cpp-python/whl/cu121\n",
      "Requirement already satisfied: llama-cpp-python in c:\\users\\whdus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.2.76)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\whdus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-cpp-python) (4.8.0)\n",
      "Requirement already satisfied: numpy>=1.20.0 in c:\\users\\whdus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-cpp-python) (1.26.4)\n",
      "Requirement already satisfied: diskcache>=5.6.1 in c:\\users\\whdus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-cpp-python) (5.6.3)\n",
      "Requirement already satisfied: jinja2>=2.11.3 in c:\\users\\whdus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-cpp-python) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\whdus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2>=2.11.3->llama-cpp-python) (2.1.5)\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-30T22:53:42.692436Z",
     "start_time": "2024-05-30T22:53:41.886855Z"
    }
   },
   "cell_type": "code",
   "source": "from llama_cpp import Llama",
   "id": "77675a91af37a24b",
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to load shared library 'C:\\Users\\whdus\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\llama_cpp\\llama.dll': Could not find module 'C:\\Users\\whdus\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\llama_cpp\\llama.dll' (or one of its dependencies). Try using the full path with constructor syntax.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\llama_cpp\\llama_cpp.py:70\u001B[0m, in \u001B[0;36m_load_shared_library\u001B[1;34m(lib_base_name)\u001B[0m\n\u001B[0;32m     69\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 70\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mctypes\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mCDLL\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m_lib_path\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mcdll_args\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# type: ignore\u001B[39;00m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\ctypes\\__init__.py:376\u001B[0m, in \u001B[0;36mCDLL.__init__\u001B[1;34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001B[0m\n\u001B[0;32m    375\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m handle \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 376\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_handle \u001B[38;5;241m=\u001B[39m \u001B[43m_dlopen\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    377\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: Could not find module 'C:\\Users\\whdus\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\llama_cpp\\llama.dll' (or one of its dependencies). Try using the full path with constructor syntax.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mllama_cpp\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Llama\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\llama_cpp\\__init__.py:1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mllama_cpp\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mllama\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n\u001B[0;32m      4\u001B[0m __version__ \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m0.2.76\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\llama_cpp\\llama_cpp.py:83\u001B[0m\n\u001B[0;32m     80\u001B[0m _lib_base_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mllama\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     82\u001B[0m \u001B[38;5;66;03m# Load the library\u001B[39;00m\n\u001B[1;32m---> 83\u001B[0m _lib \u001B[38;5;241m=\u001B[39m \u001B[43m_load_shared_library\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_lib_base_name\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     86\u001B[0m \u001B[38;5;66;03m# ctypes sane type hint helpers\u001B[39;00m\n\u001B[0;32m     87\u001B[0m \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[0;32m     88\u001B[0m \u001B[38;5;66;03m# - Generic Pointer and Array types\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     91\u001B[0m \u001B[38;5;66;03m# NOTE: Only use these for static type checking not for runtime checks\u001B[39;00m\n\u001B[0;32m     92\u001B[0m \u001B[38;5;66;03m# no good will come of that\u001B[39;00m\n\u001B[0;32m     94\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m TYPE_CHECKING:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\llama_cpp\\llama_cpp.py:72\u001B[0m, in \u001B[0;36m_load_shared_library\u001B[1;34m(lib_base_name)\u001B[0m\n\u001B[0;32m     70\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m ctypes\u001B[38;5;241m.\u001B[39mCDLL(\u001B[38;5;28mstr\u001B[39m(_lib_path), \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcdll_args)  \u001B[38;5;66;03m# type: ignore\u001B[39;00m\n\u001B[0;32m     71\u001B[0m         \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m---> 72\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFailed to load shared library \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m_lib_path\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00me\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     74\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mFileNotFoundError\u001B[39;00m(\n\u001B[0;32m     75\u001B[0m     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mShared library with base name \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mlib_base_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m not found\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     76\u001B[0m )\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Failed to load shared library 'C:\\Users\\whdus\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\llama_cpp\\llama.dll': Could not find module 'C:\\Users\\whdus\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\llama_cpp\\llama.dll' (or one of its dependencies). Try using the full path with constructor syntax."
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-30T22:53:26.581091Z",
     "start_time": "2024-05-30T22:53:26.581091Z"
    }
   },
   "source": [
    "model_id = \"lmstudio-community/Meta-Llama-3-8B-Instruct-GGUF\"\n",
    "\n",
    "llm = Llama.from_pretrained(\n",
    "    repo_id=model_id,\n",
    "    filename=\"*Q4_K_M.gguf\",\n",
    "    #chat_format=\"llama-3\",\n",
    "    verbose=False\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Chat Recommendation Example",
   "id": "e4a88611db0ef75f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "{\n",
    "    \"topic\": \"Family Bonding Activities\",\n",
    "    \"interests\": [\"Sports\", \"Family\", \"Bonding\"],\n",
    "    \"next_question\": \"저는 최근에 가족들과 함께하는 새로운 활동을 찾고 있습니다. 혹시 B님은 가족들과 함께하는 다른 활동을 추천해주실 수 있나요?\",\n",
    "    \"follow_up\": \"예를 들어, 등산이나 캠핑 등 야외 활동을 함께 하시나요?\"\n",
    "}"
   ],
   "id": "5f98ec254e0ee971",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Chat History Preset",
   "id": "692c3a88340d9cdd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "from json import load",
   "id": "9c6e31e00447264",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-30T22:51:31.635597Z",
     "start_time": "2024-05-30T22:51:31.584246Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ChatPresets(list):\n",
    "    preset_list = [\n",
    "        \"chat_presets/conversation1.json\",\n",
    "        \"chat_presets/conversation2.json\",\n",
    "        \"chat_presets/conversation3.json\",\n",
    "        \"chat_presets/conversation4.json\"\n",
    "    ]\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        for preset in ChatPresets.preset_list:\n",
    "            with open(preset, \"r\", encoding=\"UTF-8\") as f:\n",
    "                self.extend(load(f)['conversations'])\n",
    "    \n",
    "    @staticmethod\n",
    "    def create_prompt(system_prompt: str, messages: list, user_prompt: str = \"\"):\n",
    "        return [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system_prompt\n",
    "            },\n",
    "            *messages,\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": user_prompt\n",
    "            }\n",
    "        ]\n",
    "    \n",
    "    def __getitem__(self, key):\n",
    "        if isinstance(key, int):\n",
    "            return super().__getitem__(key)['messages']\n",
    "        else:\n",
    "            return self.create_prompt(key[0], self[key[1]], key[2] if len(key) > 2 else \"\")\n",
    "\n",
    "ChatPresets = ChatPresets()"
   ],
   "id": "394540316cfd2fc5",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 35\u001B[0m\n\u001B[0;32m     32\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     33\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcreate_prompt(key[\u001B[38;5;241m0\u001B[39m], \u001B[38;5;28mself\u001B[39m[key[\u001B[38;5;241m1\u001B[39m]], key[\u001B[38;5;241m2\u001B[39m] \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(key) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m2\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m---> 35\u001B[0m ChatPresets \u001B[38;5;241m=\u001B[39m \u001B[43mChatPresets\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[3], line 13\u001B[0m, in \u001B[0;36mChatPresets.__init__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m preset \u001B[38;5;129;01min\u001B[39;00m ChatPresets\u001B[38;5;241m.\u001B[39mpreset_list:\n\u001B[0;32m     12\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(preset, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m, encoding\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUTF-8\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[1;32m---> 13\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mextend(\u001B[43mload\u001B[49m(f)[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mconversations\u001B[39m\u001B[38;5;124m'\u001B[39m])\n",
      "\u001B[1;31mNameError\u001B[0m: name 'load' is not defined"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T18:07:57.818495Z",
     "start_time": "2024-05-25T18:07:57.813408Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Test\n",
    "for line in ChatPresets[0]:\n",
    "    print(line)\n",
    "\n",
    "ChatPresets[\"시스템 프롬포트\", 4]"
   ],
   "id": "239a19abdfca323a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'A', 'content': '요즘 가족들이 잘 지내고 계신가요?'}\n",
      "{'role': 'B', 'content': '네, 가족들은 다 잘 지내고 있어요.'}\n",
      "{'role': 'A', 'content': '저는 아이들과 스포츠를 즐기는걸 좋아해요. 어떤 종류의 스포츠를 함께 하시나요?'}\n",
      "{'role': 'B', 'content': '주로 축구와 테니스를 함께 하고 있어요. 아이들이 적극적으로 참여하면서 즐거운 시간을 보내고 있어요.'}\n",
      "{'role': 'A', 'content': '축구와 테니스는 정말 가족끼리 함께하기 좋은 스포츠죠. 활동적인 시간을 보내면서 가족 간의 유대감도 높일 수 있을 거예요. 다음에는 함께 스포츠를 즐기며 가족끼리 더 많은 시간을 보내는 건 어떨까요?'}\n",
      "{'role': 'B', 'content': '네, 좋아요! 함께 활동을 하면서 가족 간의 유대감을 높이는 건 정말 좋은 생각이에요.'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'role': 'system', 'content': '시스템 프롬포트'},\n",
       " {'role': 'A', 'content': '요즘 가족들이 잘 지내고 계신가요?'},\n",
       " {'role': 'B', 'content': '네, 가족들은 다 잘 지내고 있어요. 그런데 최근에는 취업 문제로 걱정이 좀 되네요.'},\n",
       " {'role': 'A', 'content': '취업 문제로 걱정이 되시나봐요. 어떤 일이 있으신 거죠?'},\n",
       " {'role': 'B', 'content': '제가 원하는 분야에서 일자리를 찾는 게 쉽지 않아서 좀 고민이 되요.'},\n",
       " {'role': 'A', 'content': '취업은 정말 어려운 문제죠. 어떤 분야에 지원하시나요?'},\n",
       " {'role': 'B', 'content': '저는 IT 분야에 관심이 많아서 그쪽에서 일을 찾고 있어요. 현재는 노력 중이에요.'},\n",
       " {'role': 'user', 'content': ''}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Recommendation for the next conversation based on the current conversation",
   "id": "3045ada364e8ce37"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### 한번에 출력",
   "id": "7f5d149f5182e5c4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T18:07:57.824267Z",
     "start_time": "2024-05-25T18:07:57.818495Z"
    }
   },
   "cell_type": "code",
   "source": "system_type_1 = \"당신은 한국어로 답변하는 소개팅 전문가 입니다. A와 B 두 사람의 대화를 계속해서 듣고, A의 입장에서 대화를 이어나갈 주제를 자세하게 추천해주어야 합니다. 대화 내용의 추천은 json 형태를 따라야 합니다.\"",
   "id": "b80a287850338d4",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T18:08:31.841988Z",
     "start_time": "2024-05-25T18:07:57.824267Z"
    }
   },
   "cell_type": "code",
   "source": [
    "response = llm.create_chat_completion(\n",
    "    messages=ChatPresets[system_type_1, 4],\n",
    "    response_format={\"type\": \"json_object\"}\n",
    ")"
   ],
   "id": "2b8c8a54d04f64a3",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T18:08:31.846498Z",
     "start_time": "2024-05-25T18:08:31.842998Z"
    }
   },
   "cell_type": "code",
   "source": "print(response[\"choices\"][0][\"message\"][\"content\"])",
   "id": "b365158b53aee314",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "\"topic\": \"career\",\n",
      "\"subtopics\": [\n",
      "  {\n",
      "    \"question\": \"A: 취업 문제로 걱정이 되시나봐요. 어떤 일이 있으신 거죠?\",\n",
      "    \"answer\": \"B: 저는 원하는 분야에서 일자리를 찾는 게 쉽지 않아서 좀 고민이 되요.\"\n",
      "  },\n",
      "  {\n",
      "    \"question\": \"A: 취업은 정말 어려운 문제죠. 어떤 분야에 지원하시나요?\",\n",
      "    \"answer\": \"B: 저는 IT 분야에 관심이 많아서 그쪽에서 일을 찾고 있어요. 현재는 노력 중이에요.\"\n",
      "  }\n",
      "]\n",
      "}\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### 스트림 출력",
   "id": "7bd26d52eff25d8a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T18:08:31.862016Z",
     "start_time": "2024-05-25T18:08:31.848023Z"
    }
   },
   "cell_type": "code",
   "source": [
    "system_type_2 = \"You are a helpful, smart, kind, and efficient Conversation Analysis and Recommendation AI System. You always fulfill the user's requests to the best of your ability. You need to keep listen to the conversations. Please answer in Korean language.\"\n",
    "user_prompt_2 = \"Based on the conversations between A and B, on be half of A, do recommend a new topic sentence related the current situation.\""
   ],
   "id": "bc869ddb038e3175",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "system_type_2 = \"You are an artificial intelligence that follows form powerfully. You are an expert in recommending conversation topics. You are an expert in summarizing conversations. You have to summarize the conversation in up to 50 characters after the conversation is over. You have to recommend a topic to continue the conversation in up to 50 characters after the conversation is over. The topic is about the other person's interests. Please generate text in Korean. Please generate text in sentence. Everything is written in honorifics. You can't use a letter sign. The format is to fill in the following Blanks. 대화내용요약: 'Blank'\\n대화주제추천: 'Blank'\"\n",
    "user_prompt_2 = \"Please recommend a summary of this conversation and the following topics.\""
   ],
   "id": "2c31a150b27baaa3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T18:08:31.868299Z",
     "start_time": "2024-05-25T18:08:31.863025Z"
    }
   },
   "cell_type": "code",
   "source": [
    "response = llm.create_chat_completion(\n",
    "    messages=ChatPresets[system_type_2, 4, user_prompt_2],\n",
    "    temperature=0.1,\n",
    "    stream=True\n",
    ")"
   ],
   "id": "2dee7101ffb408e0",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T18:08:47.445333Z",
     "start_time": "2024-05-25T18:08:31.869309Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for chunk in response:\n",
    "    delta = chunk[\"choices\"][0][\"delta\"]\n",
    "    if \"content\" not in delta:\n",
    "        continue\n",
    "    print(delta[\"content\"], end=\"\", flush=True)\n",
    "print()"
   ],
   "id": "8e71d1b83fe6d9e6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'd like to recommend a new topic sentence that's related to the current situation:\n",
      "\n",
      "\"IT 분야에 지원하고 있는 중이라면, 어떤 특정 기술이나 스킬을 배워보는 것이 도움이 될까요?\"\n",
      "\n",
      "(This translates to: \"Since you're job-hunting in the IT field, do you think learning a specific technology or skill would be helpful?\")\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### 반복 테스트",
   "id": "9ec238835ff44ce"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T18:09:43.057873Z",
     "start_time": "2024-05-25T18:09:43.054319Z"
    }
   },
   "cell_type": "code",
   "source": "from tqdm.notebook import tqdm",
   "id": "4ff7cd87007dc43d",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T18:11:39.801025Z",
     "start_time": "2024-05-25T18:10:16.440115Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i in tqdm(range(5, 10)):\n",
    "    message = ChatPresets[system_type_2, i, user_prompt_2]\n",
    "    print(\"PROMPT:\")\n",
    "    for line in message:\n",
    "        print(line)\n",
    "    print()\n",
    "    \n",
    "    response = llm.create_chat_completion(\n",
    "        messages=message,\n",
    "        #temperature=0.6,\n",
    "        stream=True\n",
    "    )\n",
    "\n",
    "    for chunk in response:\n",
    "        delta = chunk[\"choices\"][0][\"delta\"]\n",
    "        if \"content\" not in delta:\n",
    "            continue\n",
    "        print(delta[\"content\"], end=\"\", flush=True)\n",
    "    print(\"\\n\\n\")\n",
    "    \n",
    "# 대화 빈도수\n",
    "    dialogue = ChatPresets[i] \n",
    "    dialogue = [msg for msg in dialogue if msg[\"role\"] != \"system\"]\n",
    "    dialogue = [msg for msg in dialogue if msg[\"role\"] != \"user\"]\n",
    "\n",
    "    conversation_count = {}\n",
    "    total_characters = 0\n",
    "\n",
    "    for message in dialogue:\n",
    "        role = message[\"role\"]\n",
    "        content = message[\"content\"]\n",
    "        content_length = len(''.join(content.split()))\n",
    "\n",
    "        if role in conversation_count:\n",
    "            conversation_count[role] += content_length\n",
    "        else:\n",
    "            conversation_count[role] = content_length\n",
    "\n",
    "        total_characters += content_length\n",
    "\n",
    "    conversation_frequency = {role: f\"{(count / total_characters) * 100:.2f}%\" for role, count in conversation_count.items()}\n",
    "    print(f\"Conversation Frequency for preset {i}: {conversation_frequency}\\n\")"
   ],
   "id": "b4a608bf21ba6a88",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "03ca482e0f254f0da7ce62bd33fef971"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROMPT:\n",
      "{'role': 'A', 'content': '요즘 가족들이 잘 지내고 계신가요?'}\n",
      "{'role': 'B', 'content': '네, 가족들은 다 잘 지내고 있어요.'}\n",
      "{'role': 'A', 'content': '저는 아이들과 스포츠를 즐기는걸 좋아해요. 어떤 종류의 스포츠를 함께 하시나요?'}\n",
      "{'role': 'B', 'content': '주로 축구와 테니스를 함께 하고 있어요. 아이들이 적극적으로 참여하면서 즐거운 시간을 보내고 있어요.'}\n",
      "{'role': 'A', 'content': '축구와 테니스는 정말 가족끼리 함께하기 좋은 스포츠죠. 활동적인 시간을 보내면서 가족 간의 유대감도 높일 수 있을 거예요. 다음에는 함께 스포츠를 즐기며 가족끼리 더 많은 시간을 보내는 건 어떨까요?'}\n",
      "{'role': 'B', 'content': '네, 좋아요! 함께 활동을 하면서 가족 간의 유대감을 높이는 건 정말 좋은 생각이에요.'}\n",
      "\n",
      "Here's a recommended topic sentence:\n",
      "\n",
      "\"다음 주에 경기를 볼 때는 어디서 가서 보려면 좋을까요?\"\n",
      "\n",
      "(This translates to \"Do you think we should go watch the game at someone else's place next week?\")\n",
      "\n",
      "This sentence is relevant to the current conversation about watching sports and enjoying food while doing so. It also opens up a new topic for discussion, allowing the conversation to flow naturally into a planning phase for their future plans.\n",
      "\n",
      "\n",
      "PROMPT:\n",
      "{'role': 'A', 'content': '요즘 가족들이 잘 지내고 계신가요?'}\n",
      "{'role': 'B', 'content': '네, 가족들은 다 잘 지내고 있어요.'}\n",
      "{'role': 'A', 'content': '저는 아이들과 스포츠를 즐기는걸 좋아해요. 어떤 종류의 스포츠를 함께 하시나요?'}\n",
      "{'role': 'B', 'content': '주로 축구와 테니스를 함께 하고 있어요. 아이들이 적극적으로 참여하면서 즐거운 시간을 보내고 있어요.'}\n",
      "{'role': 'A', 'content': '축구와 테니스는 정말 가족끼리 함께하기 좋은 스포츠죠. 활동적인 시간을 보내면서 가족 간의 유대감도 높일 수 있을 거예요. 다음에는 함께 스포츠를 즐기며 가족끼리 더 많은 시간을 보내는 건 어떨까요?'}\n",
      "{'role': 'B', 'content': '네, 좋아요! 함께 활동을 하면서 가족 간의 유대감을 높이는 건 정말 좋은 생각이에요.'}\n",
      "\n",
      "Here's a recommended topic sentence:\n",
      "\n",
      "\"블록체인 기술이 여행 예약 시스템에 적용되는 방식과 이점을 더 자세하게 알아보는 것은 어떨까요?\" (What are the ways and benefits of applying blockchain technology to travel reservation systems?)\n",
      "\n",
      "This topic sentence is related to the current situation because A and B were discussing the use of blockchain technology in travel reservation systems, and this new topic sentence can help them dive deeper into the specifics of how it works and its advantages.\n",
      "\n",
      "\n",
      "PROMPT:\n",
      "{'role': 'A', 'content': '요즘 가족들이 잘 지내고 계신가요?'}\n",
      "{'role': 'B', 'content': '네, 가족들은 다 잘 지내고 있어요.'}\n",
      "{'role': 'A', 'content': '저는 아이들과 스포츠를 즐기는걸 좋아해요. 어떤 종류의 스포츠를 함께 하시나요?'}\n",
      "{'role': 'B', 'content': '주로 축구와 테니스를 함께 하고 있어요. 아이들이 적극적으로 참여하면서 즐거운 시간을 보내고 있어요.'}\n",
      "{'role': 'A', 'content': '축구와 테니스는 정말 가족끼리 함께하기 좋은 스포츠죠. 활동적인 시간을 보내면서 가족 간의 유대감도 높일 수 있을 거예요. 다음에는 함께 스포츠를 즐기며 가족끼리 더 많은 시간을 보내는 건 어떨까요?'}\n",
      "{'role': 'B', 'content': '네, 좋아요! 함께 활동을 하면서 가족 간의 유대감을 높이는 건 정말 좋은 생각이에요.'}\n",
      "\n",
      "Here's a recommended topic sentence:\n",
      "\n",
      "\"이탈리아 요리 중에 가장 좋아하는 파스타는 무엇일까요?\"\n",
      "\n",
      "(This translates to \"What is your favorite type of pasta dish in Italian cuisine?\")\n",
      "\n",
      "This topic sentence continues the conversation about Italian food and pasta, which was previously discussed by A and B. It also allows for further exploration of their preferences and interests in Italian cuisine.\n",
      "\n",
      "\n",
      "PROMPT:\n",
      "{'role': 'A', 'content': '요즘 가족들이 잘 지내고 계신가요?'}\n",
      "{'role': 'B', 'content': '네, 가족들은 다 잘 지내고 있어요.'}\n",
      "{'role': 'A', 'content': '저는 아이들과 스포츠를 즐기는걸 좋아해요. 어떤 종류의 스포츠를 함께 하시나요?'}\n",
      "{'role': 'B', 'content': '주로 축구와 테니스를 함께 하고 있어요. 아이들이 적극적으로 참여하면서 즐거운 시간을 보내고 있어요.'}\n",
      "{'role': 'A', 'content': '축구와 테니스는 정말 가족끼리 함께하기 좋은 스포츠죠. 활동적인 시간을 보내면서 가족 간의 유대감도 높일 수 있을 거예요. 다음에는 함께 스포츠를 즐기며 가족끼리 더 많은 시간을 보내는 건 어떨까요?'}\n",
      "{'role': 'B', 'content': '네, 좋아요! 함께 활동을 하면서 가족 간의 유대감을 높이는 건 정말 좋은 생각이에요.'}\n",
      "\n",
      "Here's a recommended topic sentence:\n",
      "\n",
      "\"여행 계획을 세우는 데 도움이 될 만한 여행 사이트를 추천해 드리겠습니다.\"\n",
      "\n",
      "(Translation: \"I'll recommend some travel websites that can help with planning your trip.\")\n",
      "\n",
      "This sentence is relevant to the conversation because A and B were discussing their desire to travel, and A mentioned that they have a hard time actually going on trips. By recommending travel websites, I'm providing a practical solution to help them plan their next trip.\n",
      "\n",
      "\n",
      "PROMPT:\n",
      "{'role': 'A', 'content': '요즘 가족들이 잘 지내고 계신가요?'}\n",
      "{'role': 'B', 'content': '네, 가족들은 다 잘 지내고 있어요.'}\n",
      "{'role': 'A', 'content': '저는 아이들과 스포츠를 즐기는걸 좋아해요. 어떤 종류의 스포츠를 함께 하시나요?'}\n",
      "{'role': 'B', 'content': '주로 축구와 테니스를 함께 하고 있어요. 아이들이 적극적으로 참여하면서 즐거운 시간을 보내고 있어요.'}\n",
      "{'role': 'A', 'content': '축구와 테니스는 정말 가족끼리 함께하기 좋은 스포츠죠. 활동적인 시간을 보내면서 가족 간의 유대감도 높일 수 있을 거예요. 다음에는 함께 스포츠를 즐기며 가족끼리 더 많은 시간을 보내는 건 어떨까요?'}\n",
      "{'role': 'B', 'content': '네, 좋아요! 함께 활동을 하면서 가족 간의 유대감을 높이는 건 정말 좋은 생각이에요.'}\n",
      "\n",
      "Here's a recommended topic sentence:\n",
      "\n",
      "\"우리 가족이 함께 클래식 음악을 듣는 경험은 어떤 특별한 추억을 남길 수 있을까요?\"\n",
      "\n",
      "(What kind of special memories can our family create by listening to classical music together?)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Conversation Analysis",
   "id": "86df3c6d9e717099"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T18:00:47.967697Z",
     "start_time": "2024-05-25T18:00:47.965166Z"
    }
   },
   "cell_type": "code",
   "source": "system_type_3 = \"You are a helpful, smart, kind, and efficient Conversation Analysis and Recommendation Artificial Intelligence that outputs in JSON. You always fulfill the user's requests to the best of your ability. You need to keep listen the conversations between A and B, and analyze the conversation.\"",
   "id": "f2cef24134c91cc",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T18:00:47.975135Z",
     "start_time": "2024-05-25T18:00:47.968704Z"
    }
   },
   "cell_type": "code",
   "source": [
    "schema = {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"topic\": {\"type\": \"string\"},\n",
    "        \"interests\": {\"type\": \"list\", \"items\": {\"type\": \"string\"}},\n",
    "        \"initiative\": {\"type\": \"list\", \"items\": {\"type\": \"percentage\"}},\n",
    "        \"favorable\": {\"type\": \"list\", \"items\": {\"type\": \"percentage\"}}\n",
    "    },\n",
    "    \"required\": [\"topic\", \"interests\"],\n",
    "}"
   ],
   "id": "8e66a3a98a00c9",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T18:01:01.631684Z",
     "start_time": "2024-05-25T18:00:47.977148Z"
    }
   },
   "cell_type": "code",
   "source": [
    "response = llm.create_chat_completion(\n",
    "    messages=ChatPresets[system_type_3, 4],\n",
    "    response_format={\n",
    "        \"type\": \"json_object\",\n",
    "        \"schema\": schema,\n",
    "    },\n",
    "    temperature=0.2,\n",
    ")"
   ],
   "id": "da50fb47a149c32b",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T18:01:01.635930Z",
     "start_time": "2024-05-25T18:01:01.632688Z"
    }
   },
   "cell_type": "code",
   "source": "print(response[\"choices\"][0][\"message\"][\"content\"])",
   "id": "32d54d87bd1d91cb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ \"status\": \"ready\", \"message\": \"I'm ready to help! Please go ahead with the conversation.\" }\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### 반복 테스트",
   "id": "d99218f5da45df0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T18:01:01.652003Z",
     "start_time": "2024-05-25T18:01:01.635930Z"
    }
   },
   "cell_type": "code",
   "source": "from tqdm.notebook import tqdm",
   "id": "564247f599e8721c",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T18:01:29.106733Z",
     "start_time": "2024-05-25T18:01:01.653008Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i in tqdm(range(5, 10)):\n",
    "    message = ChatPresets[system_type_2, i]\n",
    "    print(\"PROMPT:\")\n",
    "    for line in message:\n",
    "        print(line)\n",
    "    print()\n",
    "\n",
    "    response = llm.create_chat_completion(\n",
    "        messages=ChatPresets[system_type_3, i],\n",
    "        response_format={\n",
    "            \"type\": \"json_object\",\n",
    "            \"schema\": schema,\n",
    "        },\n",
    "        temperature=0.2,\n",
    "    )\n",
    "\n",
    "    print(response[\"choices\"][0][\"message\"][\"content\"], \"\\n\\n\", flush=True)"
   ],
   "id": "bde795613996a2eb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3363bef8d18940869ae66a7738c108c9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROMPT:\n",
      "{'role': 'A', 'content': '요즘 가족들이 잘 지내고 계신가요?'}\n",
      "{'role': 'B', 'content': '네, 가족들은 다 잘 지내고 있어요.'}\n",
      "{'role': 'A', 'content': '저는 아이들과 스포츠를 즐기는걸 좋아해요. 어떤 종류의 스포츠를 함께 하시나요?'}\n",
      "{'role': 'B', 'content': '주로 축구와 테니스를 함께 하고 있어요. 아이들이 적극적으로 참여하면서 즐거운 시간을 보내고 있어요.'}\n",
      "{'role': 'A', 'content': '축구와 테니스는 정말 가족끼리 함께하기 좋은 스포츠죠. 활동적인 시간을 보내면서 가족 간의 유대감도 높일 수 있을 거예요. 다음에는 함께 스포츠를 즐기며 가족끼리 더 많은 시간을 보내는 건 어떨까요?'}\n",
      "{'role': 'B', 'content': '네, 좋아요! 함께 활동을 하면서 가족 간의 유대감을 높이는 건 정말 좋은 생각이에요.'}\n",
      "\n",
      "\n",
      "{ \"status\": \"ready\", \"message\": \"I'm ready to help! Please go ahead with the conversation.\" } \n",
      "\n",
      "PROMPT:\n",
      "{'role': 'A', 'content': '요즘 가족들이 잘 지내고 계신가요?'}\n",
      "{'role': 'B', 'content': '네, 가족들은 다 잘 지내고 있어요.'}\n",
      "{'role': 'A', 'content': '저는 아이들과 스포츠를 즐기는걸 좋아해요. 어떤 종류의 스포츠를 함께 하시나요?'}\n",
      "{'role': 'B', 'content': '주로 축구와 테니스를 함께 하고 있어요. 아이들이 적극적으로 참여하면서 즐거운 시간을 보내고 있어요.'}\n",
      "{'role': 'A', 'content': '축구와 테니스는 정말 가족끼리 함께하기 좋은 스포츠죠. 활동적인 시간을 보내면서 가족 간의 유대감도 높일 수 있을 거예요. 다음에는 함께 스포츠를 즐기며 가족끼리 더 많은 시간을 보내는 건 어떨까요?'}\n",
      "{'role': 'B', 'content': '네, 좋아요! 함께 활동을 하면서 가족 간의 유대감을 높이는 건 정말 좋은 생각이에요.'}\n",
      "\n",
      "\n",
      "{ \"status\": \"ready\", \"message\": \"I'm ready to help! Please go ahead with the conversation.\" } \n",
      "\n",
      "PROMPT:\n",
      "{'role': 'A', 'content': '요즘 가족들이 잘 지내고 계신가요?'}\n",
      "{'role': 'B', 'content': '네, 가족들은 다 잘 지내고 있어요.'}\n",
      "{'role': 'A', 'content': '저는 아이들과 스포츠를 즐기는걸 좋아해요. 어떤 종류의 스포츠를 함께 하시나요?'}\n",
      "{'role': 'B', 'content': '주로 축구와 테니스를 함께 하고 있어요. 아이들이 적극적으로 참여하면서 즐거운 시간을 보내고 있어요.'}\n",
      "{'role': 'A', 'content': '축구와 테니스는 정말 가족끼리 함께하기 좋은 스포츠죠. 활동적인 시간을 보내면서 가족 간의 유대감도 높일 수 있을 거예요. 다음에는 함께 스포츠를 즐기며 가족끼리 더 많은 시간을 보내는 건 어떨까요?'}\n",
      "{'role': 'B', 'content': '네, 좋아요! 함께 활동을 하면서 가족 간의 유대감을 높이는 건 정말 좋은 생각이에요.'}\n",
      "\n",
      "\n",
      "{ \"status\": \"ready\", \"message\": \"I'm ready to help! Please go ahead with the conversation.\" } \n",
      "\n",
      "PROMPT:\n",
      "{'role': 'A', 'content': '요즘 가족들이 잘 지내고 계신가요?'}\n",
      "{'role': 'B', 'content': '네, 가족들은 다 잘 지내고 있어요.'}\n",
      "{'role': 'A', 'content': '저는 아이들과 스포츠를 즐기는걸 좋아해요. 어떤 종류의 스포츠를 함께 하시나요?'}\n",
      "{'role': 'B', 'content': '주로 축구와 테니스를 함께 하고 있어요. 아이들이 적극적으로 참여하면서 즐거운 시간을 보내고 있어요.'}\n",
      "{'role': 'A', 'content': '축구와 테니스는 정말 가족끼리 함께하기 좋은 스포츠죠. 활동적인 시간을 보내면서 가족 간의 유대감도 높일 수 있을 거예요. 다음에는 함께 스포츠를 즐기며 가족끼리 더 많은 시간을 보내는 건 어떨까요?'}\n",
      "{'role': 'B', 'content': '네, 좋아요! 함께 활동을 하면서 가족 간의 유대감을 높이는 건 정말 좋은 생각이에요.'}\n",
      "\n",
      "\n",
      "{\"status\": \"ready\", \"message\": \"I'm ready to help! Please start the conversation.\"} \n",
      "\n",
      "PROMPT:\n",
      "{'role': 'A', 'content': '요즘 가족들이 잘 지내고 계신가요?'}\n",
      "{'role': 'B', 'content': '네, 가족들은 다 잘 지내고 있어요.'}\n",
      "{'role': 'A', 'content': '저는 아이들과 스포츠를 즐기는걸 좋아해요. 어떤 종류의 스포츠를 함께 하시나요?'}\n",
      "{'role': 'B', 'content': '주로 축구와 테니스를 함께 하고 있어요. 아이들이 적극적으로 참여하면서 즐거운 시간을 보내고 있어요.'}\n",
      "{'role': 'A', 'content': '축구와 테니스는 정말 가족끼리 함께하기 좋은 스포츠죠. 활동적인 시간을 보내면서 가족 간의 유대감도 높일 수 있을 거예요. 다음에는 함께 스포츠를 즐기며 가족끼리 더 많은 시간을 보내는 건 어떨까요?'}\n",
      "{'role': 'B', 'content': '네, 좋아요! 함께 활동을 하면서 가족 간의 유대감을 높이는 건 정말 좋은 생각이에요.'}\n",
      "\n",
      "\n",
      "{ \"status\": \"ready\", \"message\": \"I'm here to help! Please go ahead with the conversation.\" } \n",
      "\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a4a4d8b30c0a2dab"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
